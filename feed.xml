<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/posts</id>
  <link href="http://blog.url.com/posts"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2016-11-28T00:00:00+08:00</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>Indexing Elasticsearch via Apache Pig</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/11/28/apache-pig-index-elasticsearch/"/>
    <id>http://blog.url.com/posts/2016/11/28/apache-pig-index-elasticsearch/</id>
    <published>2016-11-28T00:00:00+08:00</published>
    <updated>2016-12-02T22:45:28+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Coming soon!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>AWS ElasticSearch Service, Elastic Cloud and Self-Managed</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/11/22/aws-elasticsearch-elastic-cloud-self-managed/"/>
    <id>http://blog.url.com/posts/2016/11/22/aws-elasticsearch-elastic-cloud-self-managed/</id>
    <published>2016-11-22T00:00:00+08:00</published>
    <updated>2016-12-02T23:01:16+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;From past experience, I found the maintenance and tuning of a Elastisearch cluster to be 
a little troublesome overtime. So it isn&amp;rsquo;t surprising to see hosted Elasticsearch services pop up 
one after another. Ok, to be fair, there are hosted services for nearly everything nowadays, from 
Kafka to Wordpress lol. There is really no shortage of them. Most of them provides hassle-free launching
of entire clusters within minutes and promises to offload management of the clusters along popular 
plugins pre-installed.&lt;/p&gt;

&lt;p&gt;Quite frankly, they&amp;rsquo;re welcomed services, but they do come with some caveats and I found these the hard way
when I was evaluating the services when setting up a Elasticsearch cluster at Pocketmath.&lt;/p&gt;

&lt;h3&gt;Cluster Node Discovery&lt;/h3&gt;

&lt;p&gt;With both Elastic cloud and Amazon Elasticsearch Service, and quite possibly others too, one of the problems 
I quickly ran into is that they hide all nodes in the cluster except for the publicly accessible gateway.&lt;/p&gt;

&lt;p&gt;What this means is that, you&amp;rsquo;ll need to disable discovery and only connect through the declared 
&lt;code&gt;es.nodes.wan.only&lt;/code&gt; mode, as described below in the Elasticsearch documentation.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;es.nodes.wan.only (default false)
Whether the connector is used against an Elasticsearch instance in a cloud/restricted environment 
over the WAN, such as Amazon Web Services. In this mode, the connector disables discovery and 
only connects through the declared es.nodes during all operations, including reads and writes. 

Note that in this mode, performance is highly affected.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With Elastic Cloud, the problems ended here. Although, as a side note: if you are planning on 
indexing from an AWS instance to Elastic Cloud though, re-consider that. The speed of indexing 
to Elastic Cloud is &lt;em&gt;orders of magnitudes&lt;/em&gt; slower than indexing among Amazon web services.&lt;/p&gt;

&lt;h3&gt;AWS ElasticSearch Service and IAM Roles&lt;/h3&gt;

&lt;p&gt;Unfortunately, with AWS, I encountered more problems.&lt;/p&gt;

&lt;p&gt;AWS Elasticsearch Service currently does not allow any of the commercial plugins like Shield, Watcher
and it also lacks a good access control mechanism and/or VPC access. While there are some
alternative mechanisms to control resource access but for my use-case, none of them were ideal.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Whitelisting of IPs:&lt;/strong&gt;
 This could work if the instance, which is indexing the Elasticsearch, has a static IP.  However 
for my case, I was using Apache Pig in Amazon Elastic MapReduce (EMR). It spins up task instances 
with random IPs. As you might imagine, whitelisting &lt;code&gt;54.0.0.0/8&lt;/code&gt; isn&amp;rsquo;t exactly safe :P&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;IAM roles:&lt;/strong&gt;
 I could restrict access via IAM roles. However, all requests have to be signed individually, 
and at the time of this writing, there isn&amp;rsquo;t any Pig or Hive scripts available to do that yet. To
be honest, I don&amp;rsquo;t think there are many libraries that support this right now. This has been 
confirmed by AWS.&lt;/p&gt;

&lt;h3&gt;Proxy Server&lt;/h3&gt;

&lt;p&gt;To work around this, one way is to set up a reverse proxy, which is then whitelisted via its IP
in Access Policies in AWS ElasticSearch Service. This instance will then proxy all requests from the 
indexing instance, in my case- Amazon Elastic MapReduce (EMR) cluster, to the AWS ElasticSearch Service.
It would also require an Elastic IP, so that the IP in the whitelist does not need to be constantly changed.&lt;/p&gt;

&lt;p&gt;The upside to this is that it requires relatively few changes in the code, but the problem is, 
there is a single point of weakness &amp;amp; failure- the proxy server. It does not scale well and would 
also require constant monitoring to ensure that it is not the bottleneck in performance.&lt;/p&gt;

&lt;p&gt;This method is well explained and walked-through in this &lt;a href="https://eladnava.com/secure-aws-elasticsearch-service-behind-vpc/#theworkaround"&gt;blog post&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Application or Local Proxy&lt;/h3&gt;

&lt;p&gt;This &lt;a href="https://github.com/abutaha/aws-es-proxy"&gt;github repo&lt;/a&gt; allows you to setup a small web application
layer that sits between your code and Elasticsearch. It exposes &lt;code&gt;localhost:9200&lt;/code&gt; to your app
on every instance it is running on and signs every request (based on IAM roles) before relaying 
it to Elasticsearch. This removes the need for IP-based access control and helps with the 
scaling issues by eliminating the single point of failure.&lt;/p&gt;

&lt;p&gt;A bootstrap action (for the EMR cluster) could be added to install this and run in the background:&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;
wget https://github.com/abutaha/aws-es-proxy/releases/download/v0.2/aws-es-proxy-0.2-linux-amd64

chmod +x aws-es-proxy-0.2-linux-amd64
./aws-es-proxy-0.2-linux-amd64 -endpoint https://elasticsearch.endpoint.hostname /dev/null &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With that the remote endpoint would be available via:&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;curl -XGET &lt;span class="s1"&gt;'http://localhost:9200'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Choices&lt;/h3&gt;

&lt;p&gt;While the second method is definitely feasible, in the end, in view of the issues (and workarounds) 
and the cost of equivalent instances in AWS vs AWS ElasticSearch Service and the lack of support for
plugins and later versions of Elasticsearch, I decided that managing a cluster by ourselves would 
probably be much more flexible for us in future than a hosted service with a bunch of restrictions.&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Nil, Try &amp; The Lonely Operator</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/07/28/nil-try-and-lonely-operator/"/>
    <id>http://blog.url.com/posts/2016/07/28/nil-try-and-lonely-operator/</id>
    <published>2016-07-28T00:00:00+08:00</published>
    <updated>2016-12-07T23:22:22+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Recently, I left a comment on one of my colleague&amp;rsquo;s PR and we had a discussion with him about
the use of &lt;code&gt;try&lt;/code&gt; vs the lonely operator &lt;code&gt;&amp;amp;.&lt;/code&gt; and it led to a number of conclusions personally.&lt;/p&gt;

&lt;p&gt;I used to use lots of &lt;code&gt;.try&lt;/code&gt;. I&amp;rsquo;ve also come across codebases littered with it, be it in the
presentation layer or in the models. From personal experience, I&amp;rsquo;ll say it&amp;rsquo;s pretty easy to end up with
&lt;code&gt;.try&lt;/code&gt; littered all around.&lt;/p&gt;

&lt;p&gt;I was curious about when it shouldn&amp;rsquo;t be used, and if there were better alternatives.&lt;/p&gt;

&lt;h3&gt;The Obvious Scenario&lt;/h3&gt;

&lt;p&gt;Before the lonely operator was introduced, I used &lt;code&gt;try&lt;/code&gt; in a 2 distinct scenarios. &lt;/p&gt;

&lt;p&gt;The first obvious usecase: when I am not sure if the object that I are calling the method on 
could be a &lt;code&gt;nil&lt;/code&gt; object or not. Obviously, calling any method on a &lt;code&gt;nil&lt;/code&gt; object 
rightfully throws an error during runtime. Of course, I could use something like this to avoid the
error.&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;user&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;name&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And &lt;code&gt;user.try(:name)&lt;/code&gt; yields the same result.&lt;/p&gt;

&lt;h3&gt;The Not So Obvious Scenario&lt;/h3&gt;

&lt;p&gt;Surprisingly, even when I don&amp;rsquo;t know what the object is and whether it even has that method defined or not,
I still found myself using &lt;code&gt;try&lt;/code&gt;. It still returns &lt;code&gt;nil&lt;/code&gt;. It&amp;rsquo;s like this deceivingly good and 
lazy way to sidestep &lt;code&gt;NoMethodError&lt;/code&gt;. But I find that this laziness, potentially leads to surprises 
(which obviously isn&amp;rsquo;t good).&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="c1"&gt;# Either a guest user without a name, or a registered user with a name&lt;/span&gt;
&lt;span class="n"&gt;some_user&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;try&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:name&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;The Lonely Operator&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;user&amp;amp;.name&lt;/code&gt; is equivalent to &lt;code&gt;user &amp;amp;&amp;amp; user.name&lt;/code&gt; and only this. It still throws a &lt;code&gt;NoMethodError&lt;/code&gt; 
when the method doesn&amp;rsquo;t exist on the object. And that&amp;rsquo;s good for various reasons.&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;invalid_method&lt;/span&gt; &lt;span class="c1"&gt;# throws NoMethodError&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In the event where I have no idea what the object is, it is a &lt;em&gt;clear&lt;/em&gt; sign that I should spend 
the time to refactor the code so that the object class is deterministic and 
not rely on a &lt;code&gt;.try&lt;/code&gt; to squirm out of the situation.&lt;/p&gt;

&lt;p&gt;Another nice side effect is that, the lonely operator really doesn&amp;rsquo;t look great when I chain it. 
Being huge on aesthetics and coding styles, I just end up chaining less.&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;user&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;name&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;truncate&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# this just looks clunky imo&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;All those &lt;code&gt;.try(..).try(..)&lt;/code&gt;? I always knew I should be getting rid of those too, but it was just 
so safe. &lt;a href="https://en.wikipedia.org/wiki/Law_of_Demeter"&gt;Law of Demeter&lt;/a&gt; literally screams at me 
every time. &lt;/p&gt;

&lt;p&gt;I hope this post makes you think twice the next time &lt;code&gt;.try&lt;/code&gt; chains comes to mind:P&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Capybara &amp; Waiting</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/07/27/capybara-and-waiting/"/>
    <id>http://blog.url.com/posts/2016/07/27/capybara-and-waiting/</id>
    <published>2016-07-27T00:00:00+08:00</published>
    <updated>2016-12-02T23:09:12+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;All of us do TDD or at least some form of automated testing, I hope! If you’re writing tests in Rails, 
you’re likely to be doing feature tests with &lt;a href="https://github.com/jnicklas/capybara"&gt;Capybara&lt;/a&gt; as well.&lt;/p&gt;

&lt;p&gt;Some of these slipped my mind while adding feature specs at work at 
&lt;a href="https://www.pocketmath.com/"&gt;pocketmath&lt;/a&gt; and I spent extra time that I shouldn&amp;rsquo;t have! 
So I hope this post can be a reminder to myself in future and be of help to anyone who 
encounters the same problems!&lt;/p&gt;

&lt;h3&gt;Common Scenario&lt;/h3&gt;

&lt;p&gt;Let’s look at a common scenario in a feature test: &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Load some form&lt;/li&gt;
&lt;li&gt;Click a random button&lt;/li&gt;
&lt;li&gt;Check if the refreshed page (or partially re-rendered pages) matches your expected results&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you’re just transitioning from unit tests, it might be tempting to jump right to this option:&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;visit&lt;/span&gt; &lt;span class="n"&gt;some_path&lt;/span&gt;
&lt;span class="n"&gt;click_button&lt;/span&gt; &lt;span class="s1"&gt;'Submit'&lt;/span&gt; &lt;span class="c1"&gt;# Does an AJAX request&lt;/span&gt;

&lt;span class="c1"&gt;# -- Page refresh or re-render --&lt;/span&gt;

&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#dom-id'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;text&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;to&lt;/span&gt; &lt;span class="n"&gt;eq&lt;/span&gt; &lt;span class="s1"&gt;'something'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&amp;rsquo;ll find that it doesn&amp;rsquo;t work too well (not at all actually). This is because there is a delay 
between the button click and the actual completion of the code that is run as a result of that click. &lt;/p&gt;

&lt;p&gt;It is not synchronous. It could be a page refresh, a partial render or a simple AJAX call. 
Its hard to predict how long exactly that is going to take.&lt;/p&gt;

&lt;h3&gt;Magical Built-in Matchers&lt;/h3&gt;

&lt;p&gt;For this reason, Capybara provides us with some built-in matchers. They work amazingly well 
for these scenarios where you are waiting for something to finish before checking the content for text, 
DOM elements for visibility etc. Since the start, it was designed to automatically wait for elements 
to appear or disappear on the page.&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#dom-id'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;should&lt;/span&gt; &lt;span class="n"&gt;have_content&lt;/span&gt; &lt;span class="s1"&gt;'something'&lt;/span&gt;
&lt;span class="c1"&gt;# have_css, have_selector&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can even define if the element should be visible or not after it is rendered. &lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;find&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'#dom-id'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;should&lt;/span&gt; &lt;span class="n"&gt;have_content&lt;/span&gt; &lt;span class="s1"&gt;'something'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;visible: &lt;/span&gt;&lt;span class="kp"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Magical. Right? &lt;/p&gt;

&lt;h3&gt;Old solutions&lt;/h3&gt;

&lt;p&gt;Despite the fact that the awesome Capybara matchers were there from the start, pre-2.0, many people didn&amp;rsquo;t use them.
Instead they used &lt;code&gt;wait_until { ... }&lt;/code&gt; or even &lt;code&gt;sleep(3)&lt;/code&gt; despite being clunkier solutions. 
&lt;code&gt;wait_until&lt;/code&gt; was then deprecated in Capybara v2.0 altogether.&lt;/p&gt;

&lt;h3&gt;Complications&lt;/h3&gt;

&lt;p&gt;Take a look at the scenario below, is that single &lt;code&gt;have_content&lt;/code&gt; there sufficient? What do you think?&lt;/p&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;fill_in&lt;/span&gt; &lt;span class="ss"&gt;:name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;with: &lt;/span&gt;&lt;span class="s1"&gt;'Daniel'&lt;/span&gt;
&lt;span class="n"&gt;click_button&lt;/span&gt; &lt;span class="s1"&gt;'Link'&lt;/span&gt; &lt;span class="c1"&gt;#some AJAX call happens&lt;/span&gt;
&lt;span class="n"&gt;reload_page&lt;/span&gt;
&lt;span class="n"&gt;expect&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;page&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;to&lt;/span&gt; &lt;span class="n"&gt;have_content&lt;/span&gt; &lt;span class="s1"&gt;'Linked'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Nope! There&amp;rsquo;s still a chance that the &lt;code&gt;reload_page&lt;/code&gt; would happen before the AJAX code finishes. 
And the tests would randomly fail since the content-check is dependant on the click event&amp;rsquo;s code execution.
That&amp;rsquo;s not good; we all want deterministic results for our tests, right?&lt;/p&gt;

&lt;h3&gt;What now?&lt;/h3&gt;

&lt;p&gt;So what do we do now? Well, one pretty elegant way to fix this is explained over at a thoughtbot blog post 
&lt;a href="https://robots.thoughtbot.com/automatically-wait-for-ajax-with-capybara"&gt;here&lt;/a&gt;.  Through spec 
helpers, they introduce a &lt;code&gt;wait_for_ajax&lt;/code&gt; method that was designed to be used whenever you need 
to make sure that all AJAX calls have completed before proceeding, or in this case, before the page reload.&lt;/p&gt;

&lt;h3&gt;Alternatives&lt;/h3&gt;

&lt;p&gt;Alternatively, you could also use &lt;code&gt;have_selector&lt;/code&gt; infront of the reload to block the execution. But in my opinion, 
if you don&amp;rsquo;t actually want to test the content, using &lt;code&gt;wait_for_ajax&lt;/code&gt; makes more sense. &lt;/p&gt;

&lt;p&gt;So the next time you encounter similar issues, stay calm and first check to make sure that you are 
using the Capybara built-in matchers before using &lt;code&gt;sleep&lt;/code&gt;!&lt;/p&gt;

&lt;p&gt;What does everyone think? Are your experiences similar?&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Dockerized Golang + Postgres on Digital Ocean</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/04/27/golang-docker-postgres-digital-ocean/"/>
    <id>http://blog.url.com/posts/2016/04/27/golang-docker-postgres-digital-ocean/</id>
    <published>2016-04-27T00:00:00+08:00</published>
    <updated>2016-12-02T22:58:59+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;My previous deploy on the Rails stack was a little more involved so I chose to just deploy it in the conventional capistrano way after setting the server up.&lt;/p&gt;

&lt;p&gt;But with the rise in popularity of Docker recently, I&amp;rsquo;ve been wanting to deploy something into production with Docker but never found the right app for it until this one.&lt;/p&gt;

&lt;p&gt;It was a simple Golang scraper + Api that is backed by PostgreSQL.&lt;/p&gt;

&lt;h3&gt;Overview&lt;/h3&gt;

&lt;p&gt;I went with a fresh Ubuntu 14.04 DigitalOcean droplet (yes again). Some boilerplate setup for a digital ocean instance is recorded here in a &lt;a href="https://aranair.github.io/posts/2016/01/22/capistrano-postgres-rails-rvm-nginx-puma"&gt;previous post&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;The basic idea was to have 2 Dockerized components to this deployment. The first Docker container would be running the Golang app. The second one is to run Postgres via linked data.&lt;/p&gt;

&lt;h3&gt;Dockerize the Postgres&lt;/h3&gt;

&lt;p&gt;I chose to go with a base installation of Postgres and configure it from there, but YMMV.&lt;/p&gt;

&lt;p&gt;This runs the postgres service under &lt;code&gt;db&lt;/code&gt; name and as a daemon.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker run --name db -e POSTGRES_PASSWORD=YOUR_PASSWORD -d postgres
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To setup a dedicated user for the app and create the database, I opened the bash shell into the container via: &lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker exec -it db /bin/bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;From there, a new user was created and granted privileges via psql CLI.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;psql -U postgres
&lt;/code&gt;&lt;/pre&gt;&lt;pre class="highlight plaintext"&gt;&lt;code&gt;CREATE USER app;
CREATE DATABASE appdb;
GRANT ALL PRIVILEGES ON DATABASE appdb TO app;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you try to connect the app at this point, it will fail because it does not listen to addresses outside of 127.0.0.1 and doesn&amp;rsquo;t allow client authentication in connections yet. &lt;/p&gt;

&lt;p&gt;In order for it to work, there were two files which I had to modify:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;hba_file&lt;/code&gt; - To enable client authentication&lt;/li&gt;
&lt;li&gt;&lt;code&gt;postgresql.conf&lt;/code&gt; - To enable listening of addresses other than localhost&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To find the location of the &lt;code&gt;hba_file&lt;/code&gt; simply run &lt;code&gt;show hba_file;&lt;/code&gt; in the psql interactive shell. &lt;/p&gt;

&lt;p&gt;The default one should lie at this location: &lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;/var/lib/postgresql/data/pg_hba.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Installed my favourite text editor via:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;apt-get update &amp;amp;&amp;amp; apt-get install vim
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Changed from this:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;host  all  all  127.0.0.1/32  md5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To this, so that it allows connections that are from the same machine:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;host all  all  192.168.1.0/24  md5
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For &lt;code&gt;/etc/postgresql/9.3/main/postgresql.conf&lt;/code&gt;:  Changing &lt;code&gt;#listen_addresses = &amp;#39;localhost&amp;#39;&lt;/code&gt; to &lt;code&gt;listen_addresses = &amp;#39;*&amp;#39;&lt;/code&gt; would enable it to listen for incoming connection requests from all available IP addresses.&lt;/p&gt;

&lt;p&gt;A restart of the postgres service was also required.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;sudo service postgresql stop
sudo service postgresql start
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Docker Volumes&lt;/h3&gt;

&lt;p&gt;The best practice for all dockerized database components is for it to have an external data volume so that you can always restart the container without losing the data. 
In my deployment, you&amp;rsquo;ll notice that I do not specifically set this up and that is because the &lt;a href="&amp;quot;https://github.com/docker-library/postgres/blob/8e867c8ba0fc8fd347e43ae53ddeba8e67242a53/9.3/Dockerfile&amp;quot;"&gt;Postgres Dockerfile&lt;/a&gt; already does this by default!&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ENV PATH /usr/lib/postgresql/$PG_MAJOR/bin:$PATH
ENV PGDATA /var/lib/postgresql/data
VOLUME /var/lib/postgresql/data
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can find out more about it in the &lt;a href="https://docs.docker.com/engine/userguide/containers/dockervolumes/"&gt;official documentation&lt;/a&gt; if you&amp;rsquo;re interested.&lt;/p&gt;

&lt;h3&gt;Dockerize the Golang App&lt;/h3&gt;

&lt;p&gt;This is the simple Dockerfile that I&amp;rsquo;ve used for my Golang App.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;FROM golang:onbuild

RUN go get bitbucket.org/liamstask/goose/cmd/goose

RUN ["apt-get", "update"]
RUN ["apt-get", "install", "-y", "vim"]

ADD config.toml /go/bin/
ADD dbconf.yml /go/src/app/db/

EXPOSE 5000
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A quick run through of each line:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The first line runs the &amp;lsquo;onbuild&amp;rsquo; variant of the golang image that automatically copies the source, build and run it. &lt;/li&gt;
&lt;li&gt;The second line installs &amp;#39;goose&amp;rsquo;, which is the tool I use to get (somewhat) Rails-like database migrations.&lt;/li&gt;
&lt;li&gt;Next two lines just installs Vim, and are just nice to haves when I ssh into the Docker instance to check the config files out.&lt;/li&gt;
&lt;li&gt;Then copy some app config files into the docker image.&lt;/li&gt;
&lt;li&gt;Last line simply exposes port 5000 of the container to the outside world. &lt;/li&gt;
&lt;/ul&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker built -t app
docker run -d -p 80:5000 --name gosnap --link db:postgres app
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-d&lt;/code&gt; tells it to run it as a daemon,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-p 80:5000&lt;/code&gt; tells it to link the host container&amp;rsquo;s port 80 to port 5000 of the docker container&lt;/li&gt;
&lt;li&gt;&lt;code&gt;--link db:postgres&lt;/code&gt; links our app to the postgres container that we&amp;rsquo;ve created earlier&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Via the link to the postgres container, you automatically get this environment variable &lt;code&gt;$POSTGRES_PORT_5432_TCP_ADDR&lt;/code&gt; in the app. This contains&lt;/p&gt;

&lt;p&gt;If like me, you use goose, your dbconf.yml will should look something like this at the end.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;db:
   driver: postgres
   open: host=$POSTGRES_PORT_5432_TCP_ADDR user=app dbname=appdb sslmode=disable
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I then ran the migrations at this point:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;docker exec -it gosnap goose up
&lt;/code&gt;&lt;/pre&gt;</content>
  </entry>
  <entry>
    <title>Capistrano + Postgres + Rails + RVM + Nginx + Puma on DigitalOcean</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/01/22/capistrano-postgres-rails-rvm-nginx-puma/"/>
    <id>http://blog.url.com/posts/2016/01/22/capistrano-postgres-rails-rvm-nginx-puma/</id>
    <published>2016-01-22T00:00:00+08:00</published>
    <updated>2016-12-02T22:58:28+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Recently, I&amp;rsquo;ve been working on my squash club, &lt;a href="http://www.ucsc.sg"&gt;UCSC&amp;rsquo;s new site&lt;/a&gt;. And of course, being slightly short of time, I kinda just fell back on Rails to quickly get something up for the club.&lt;/p&gt;

&lt;p&gt;Before Heroku decided to put a 7 USD price on their free tier, it was an easy default for hosting any mini prototypes or projects. Ok I admit, I&amp;rsquo;ve historically used Pingdom to avoid having the free instances spin down after 30 mins :P. &lt;/p&gt;

&lt;h3&gt;Overview of Setup&lt;/h3&gt;

&lt;p&gt;I went with a fresh Ubuntu 14.04 DigitalOcean droplet to see how long it takes for me to setup a fresh server for Rails deployment. tl;dr Its actually doesn&amp;rsquo;t take long at all :P&lt;/p&gt;

&lt;p&gt;The stack I chose was nothing out of the ordinary:
- RVM for ruby (just more used to RVM, no intention to start a war on rbenv vs rvm :P)
- Rails for application code
- Postgres for the database
- Capistrano for deployment (there really isn&amp;rsquo;t other better option imo)
- Nginx for the reverse proxy (again)
- Puma for the webserver&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve kinda just compiled the steps these posts mainly:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-14-04"&gt;Initial Server Setup&lt;/a&gt;,&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-14-04"&gt;PostgreSQL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/deploying-a-rails-app-on-ubuntu-14-04-with-capistrano-nginx-and-puma"&gt;Nginx, Puma, RVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.digitalocean.com/community/tutorials/how-to-set-up-a-host-name-with-digitalocean"&gt;Nameserver setup)&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Devise 3, Capistrano &amp;amp; Env Vars&lt;/h3&gt;

&lt;p&gt;I must admit I was stuck here for a good bit haha.&lt;/p&gt;

&lt;p&gt;So, since Devise 3, a secret key has been required on production defined in the Devise initializer:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;config.secret_key = ENV[&amp;quot;SECRET_KEY_BASE&amp;quot;] if Rails.env.production?&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;There are notably 2 ways to get this working:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Symlink configs/secrets.yml with an actual key on capistrano deploy&lt;/li&gt;
&lt;li&gt;Use &amp;ldquo;environment variables&amp;rdquo; (I assumed so after seeing ENV)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Most of the people I see fix this by using &lt;a href="https://github.com/rbenv/rbenv-vars"&gt;rbenv-var&lt;/a&gt; to manage environment variables for ruby projects but since I&amp;rsquo;m using rvm, I don&amp;rsquo;t exactly have that option.&lt;/p&gt;

&lt;p&gt;So I ssh&amp;rsquo;d into the server and did this &lt;code&gt;export $SECRET_KEY_BASE=...&lt;/code&gt; and fully expected it to work after seeing the same value with &lt;code&gt;ruby -e &amp;quot;p ENV[&amp;#39;SECRET_KEY_BASE&amp;#39;]&amp;quot;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Except it didn&amp;rsquo;t.&lt;/p&gt;

&lt;h3&gt;The Problem?&lt;/h3&gt;

&lt;p&gt;After a little digging around, I found out that when you are using Capistrano to deploy, apparently it uses SHELL variables that exist in the lifetime of the deployment (well technically its just SSH) instead of the actual environment variables.&lt;/p&gt;

&lt;p&gt;So the correct place to put the export was in &lt;code&gt;~/.bashrc&lt;/code&gt;!&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;export SECRET_KEY_BASE="xxx"
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The deployment with capistrano was relatively straightforward otherwise.&lt;/p&gt;

&lt;p&gt;Below, I&amp;rsquo;ve compiled the commands I&amp;#39;ved used (most of them) for the entire process.&lt;/p&gt;

&lt;h3&gt;Adding Deploy User&lt;/h3&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;adduser deploy
gpasswd -a deploy sudo
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Copy public key up to server&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;ssh-copy-id deploy@server_ip_address
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Install Postgres&lt;/h3&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;sudo apt-get update
sudo apt-get install postgresql postgresql-contrib
sudo -i -u postgres
createuser --interactive
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Install Nginx&lt;/h3&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;sudo apt-get install curl git-core nginx -y
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Install RVM &amp;amp; Ruby&lt;/h3&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;gpg --keyserver hkp://keys.gnupg.net --recv-keys 409B6B1796C275462A1703113804BB82D39DC0E3
curl -sSL https://get.rvm.io | bash -s stable
source ~/.rvm/scripts/rvm
rvm requirements
rvm install 2.2.1
rvm use 2.2.1 --default
gem install rails -V --no-ri --no-rdoc
gem install bundler -V --no-ri --no-rdoc
gem install pg
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Setting up SSH (Github)&lt;/h3&gt;

&lt;p&gt;&lt;code&gt;ssh -T git@github.com&lt;/code&gt; on the server then add the server&amp;rsquo;s public key into your github account.&lt;/p&gt;

&lt;h3&gt;Gemfile&lt;/h3&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;group :development do
    gem 'capistrano',         require: false
    gem 'capistrano-rvm',     require: false
    gem 'capistrano-rails',   require: false
    gem 'capistrano-bundler', require: false
    gem 'capistrano3-puma',   require: false
end

gem 'puma'
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Deploy.rb&lt;/h3&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:application&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'ucsc'&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:repo_url&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'git@github.com:aranair/ucsc.git'&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:user&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;            &lt;span class="s1"&gt;'deploy'&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_threads&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_workers&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="c1"&gt;# Don't change these unless you know what you're doing&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:pty&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;             &lt;span class="kp"&gt;true&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:use_sudo&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;        &lt;span class="kp"&gt;false&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:stage&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;           &lt;span class="ss"&gt;:production&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:deploy_via&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="ss"&gt;:remote_cache&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:deploy_to&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;       &lt;span class="s2"&gt;"/home/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:user&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/apps/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:application&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_bind&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;       &lt;span class="s2"&gt;"unix://&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;shared_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/tmp/sockets/&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:application&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;-puma.sock"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_state&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;      &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;shared_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/tmp/pids/puma.state"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_pid&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;        &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;shared_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/tmp/pids/puma.pid"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_access_log&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;release_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/log/puma.error.log"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_error_log&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;release_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/log/puma.access.log"&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:ssh_options&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="ss"&gt;forward_agent: &lt;/span&gt;&lt;span class="kp"&gt;true&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;user: &lt;/span&gt;&lt;span class="n"&gt;fetch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:user&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="ss"&gt;keys: &lt;/span&gt;&lt;span class="sx"&gt;%w(~/.ssh/id_rsa.pub)&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_preload_app&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;true&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_worker_timeout&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;nil&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:puma_init_active_record&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kp"&gt;true&lt;/span&gt;  &lt;span class="c1"&gt;# Change to false when not using ActiveRecord&lt;/span&gt;

&lt;span class="c1"&gt;## Defaults:&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:scm&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;           &lt;span class="ss"&gt;:git&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:branch&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;        &lt;span class="ss"&gt;:master&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:format&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;        &lt;span class="ss"&gt;:pretty&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:log_level&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="ss"&gt;:debug&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:keep_releases&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;5&lt;/span&gt;

&lt;span class="c1"&gt;## Linked Files &amp;amp; Directories (Default None):&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:linked_files&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="sx"&gt;%w{config/database.yml}&lt;/span&gt;
&lt;span class="n"&gt;set&lt;/span&gt; &lt;span class="ss"&gt;:linked_dirs&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;  &lt;span class="sx"&gt;%w{bin log tmp/pids tmp/cache tmp/sockets vendor/bundle public/system}&lt;/span&gt;

&lt;span class="n"&gt;namespace&lt;/span&gt; &lt;span class="ss"&gt;:puma&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="s1"&gt;'Create Directories for Puma Pids and Socket'&lt;/span&gt;
  &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="ss"&gt;:make_dirs&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;roles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:app&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
      &lt;span class="n"&gt;execute&lt;/span&gt; &lt;span class="s2"&gt;"mkdir &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;shared_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/tmp/sockets -p"&lt;/span&gt;
      &lt;span class="n"&gt;execute&lt;/span&gt; &lt;span class="s2"&gt;"mkdir &lt;/span&gt;&lt;span class="si"&gt;#{&lt;/span&gt;&lt;span class="n"&gt;shared_path&lt;/span&gt;&lt;span class="si"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/tmp/pids -p"&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="n"&gt;before&lt;/span&gt; &lt;span class="ss"&gt;:start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;:make_dirs&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;span class="n"&gt;namespace&lt;/span&gt; &lt;span class="ss"&gt;:deploy&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
  &lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="s2"&gt;"Make sure local git is in sync with remote."&lt;/span&gt;
  &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="ss"&gt;:check_revision&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;roles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:app&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
      &lt;span class="k"&gt;unless&lt;/span&gt; &lt;span class="sb"&gt;`git rev-parse HEAD`&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="sb"&gt;`git rev-parse origin/master`&lt;/span&gt;
        &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;"WARNING: HEAD is not the same as origin/master"&lt;/span&gt;
        &lt;span class="nb"&gt;puts&lt;/span&gt; &lt;span class="s2"&gt;"Run `git push` to sync changes."&lt;/span&gt;
        &lt;span class="nb"&gt;exit&lt;/span&gt;
      &lt;span class="k"&gt;end&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="s1"&gt;'Initial Deploy'&lt;/span&gt;
  &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="ss"&gt;:initial&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;roles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:app&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
      &lt;span class="n"&gt;before&lt;/span&gt; &lt;span class="s1"&gt;'deploy:restart'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;'puma:start'&lt;/span&gt;
      &lt;span class="n"&gt;invoke&lt;/span&gt; &lt;span class="s1"&gt;'deploy'&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="n"&gt;desc&lt;/span&gt; &lt;span class="s1"&gt;'Restart application'&lt;/span&gt;
  &lt;span class="n"&gt;task&lt;/span&gt; &lt;span class="ss"&gt;:restart&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
    &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;roles&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="ss"&gt;:app&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="ss"&gt;in: :sequence&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="ss"&gt;wait: &lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt; &lt;span class="k"&gt;do&lt;/span&gt;
      &lt;span class="n"&gt;invoke&lt;/span&gt; &lt;span class="s1"&gt;'puma:restart'&lt;/span&gt;
    &lt;span class="k"&gt;end&lt;/span&gt;
  &lt;span class="k"&gt;end&lt;/span&gt;

  &lt;span class="n"&gt;before&lt;/span&gt; &lt;span class="ss"&gt;:starting&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     &lt;span class="ss"&gt;:check_revision&lt;/span&gt;
  &lt;span class="n"&gt;after&lt;/span&gt;  &lt;span class="ss"&gt;:finishing&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="ss"&gt;:compile_assets&lt;/span&gt;
  &lt;span class="n"&gt;after&lt;/span&gt;  &lt;span class="ss"&gt;:finishing&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="ss"&gt;:cleanup&lt;/span&gt;
  &lt;span class="n"&gt;after&lt;/span&gt;  &lt;span class="ss"&gt;:finishing&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;    &lt;span class="ss"&gt;:restart&lt;/span&gt;
&lt;span class="k"&gt;end&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Capfile&lt;/h3&gt;
&lt;pre class="highlight ruby"&gt;&lt;code&gt;&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/setup'&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/deploy'&lt;/span&gt;

&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/rails'&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/bundler'&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/rvm'&lt;/span&gt;
&lt;span class="nb"&gt;require&lt;/span&gt; &lt;span class="s1"&gt;'capistrano/puma'&lt;/span&gt;


&lt;span class="no"&gt;Dir&lt;/span&gt;&lt;span class="p"&gt;.&lt;/span&gt;&lt;span class="nf"&gt;glob&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;'lib/capistrano/tasks/*.rake'&lt;/span&gt;&lt;span class="p"&gt;).&lt;/span&gt;&lt;span class="nf"&gt;each&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="n"&gt;import&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="p"&gt;}&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Nginx&lt;/h3&gt;

&lt;p&gt;config/nginx.conf&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;upstream puma {
  server unix:///home/deploy/apps/ucsc/shared/tmp/sockets/appname-puma.sock;
}

server {
  listen 80 default_server deferred;
  # server_name *.ucsc.sg;

  root /home/deploy/apps/ucsc/current/public;
  access_log /home/deploy/apps/ucsc/current/log/nginx.access.log;
  error_log /home/deploy/apps/ucsc/current/log/nginx.error.log info;

  location ^~ /assets/ {
    gzip_static on;
    expires max;
    add_header Cache-Control public;
  }

  try_files $uri $uri @puma;
  location @puma {
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header Host $http_host;
    proxy_redirect off;

    proxy_pass http://puma;
  }

  error_page 500 502 503 504 /500.html;
  client_max_body_size 10M;
  keepalive_timeout 10;
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;After Capistrano deploy via &lt;code&gt;ap production deploy: initial&lt;/code&gt;&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;sudo rm /etc/nginx/sites-enabled/default
sudo ln -nfs "/home/deploy/apps/ucsc/current/config/nginx.conf" "/etc/nginx/sites-enabled/ucsc"
sudo service nginx restart
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Setting it up wasn&amp;rsquo;t too hard, but it does seem a little tedious and it is really easy to forget something along the way. No wonder people are turning to ansible/chef for multi-server setups. For individual web developers though, perhaps a bash script is enough.&lt;/p&gt;

&lt;p&gt;Maybe in another post I&amp;rsquo;ll have a go at using Ansible or a bash script to automatically set the servers up.&lt;/p&gt;

&lt;p&gt;Future posts:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Ansible / Bash script to set up&lt;/li&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
</feed>
