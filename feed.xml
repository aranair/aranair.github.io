<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Blog Name</title>
  <subtitle>Blog subtitle</subtitle>
  <id>http://blog.url.com/posts</id>
  <link href="http://blog.url.com/posts"/>
  <link href="http://blog.url.com/feed.xml" rel="self"/>
  <updated>2017-03-10T00:00:00+08:00</updated>
  <author>
    <name>Blog Author</name>
  </author>
  <entry>
    <title>Tuning My Apache Spark Data Processing Cluster on Amazon EMR</title>
    <link rel="alternate" href="http://blog.url.com/posts/2017/03/10/tuning-my-apache-spark-cluster-on-aws-emr/"/>
    <id>http://blog.url.com/posts/2017/03/10/tuning-my-apache-spark-cluster-on-aws-emr/</id>
    <published>2017-03-10T00:00:00+08:00</published>
    <updated>2017-03-11T00:51:30+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Lately, I worked on some data integration at Pocketmath where I wrote a 
bunch of Spark scripts in Scala to run some transformations on a data set of about 
250GB on a monthly basis. In this post, I&amp;rsquo;ll talk about some of the 
problems I encountered, and some considerations while setting up the cluster and running
the Spark tasks.&lt;/p&gt;

&lt;h3&gt;Dataset Size&lt;/h3&gt;

&lt;p&gt;The size of the data set is about 250GB, which isn&amp;rsquo;t quite close to the scale other data 
scientist/engineers handle, but is easily one of the bigger ones for me. Nonetheless, I do think the 
transformations are on the heavy side; it involves a chain of rather expensive operations. &lt;/p&gt;

&lt;p&gt;Because of the sensitive nature of the data, I&amp;rsquo;m going to skip the nitty-gritty details of the task.
I&amp;rsquo;ll run through the kind of steps that were included in the script.&lt;/p&gt;

&lt;h3&gt;Multiple Shuffle Operations&lt;/h3&gt;

&lt;p&gt;The script starts off with multiple &lt;code&gt;JOIN&lt;/code&gt;s into a &lt;code&gt;UNION&lt;/code&gt;, &lt;code&gt;EXPLODE&lt;/code&gt;, &lt;code&gt;SORT&lt;/code&gt; within partition, 
then &lt;code&gt;GROUP&lt;/code&gt; and &lt;code&gt;COLLECT&lt;/code&gt; into another &lt;code&gt;SORT&lt;/code&gt; eventually. They&amp;rsquo;re 
&lt;em&gt;pretty&lt;/em&gt; expensive shuffle operations and as you might imagine, doing this on this data size did
pose some problems at first when I wasn&amp;rsquo;t so familar with the details of how Spark handles
memory allocations.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://s3-ap-southeast-1.amazonaws.com/homan/blog/spark-flow.png"&gt;&lt;img src="https://s3-ap-southeast-1.amazonaws.com/homan/blog/spark-flow-small.png" alt="Spark Flow Chart" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Second Difficulty&lt;/h3&gt;

&lt;p&gt;Secondly, I also had to split a file that looks like the examples below. Essentially, you can imagine 
them to be ranks or row numbers (of course, with a bunch of other data transformations)&lt;/p&gt;

&lt;p&gt;From this format:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;51abebcfab2ef2abeed2f 8,120,384,898 
21abfbbeef5791adef3f2 1,9,1214,8827 
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Into these two files:&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;# 1,2 are like IDs&lt;/span&gt;
51abebcfab2ef2abeed2f 1
21abfbbeef5791adef3f2 2
...
&lt;/code&gt;&lt;/pre&gt;&lt;pre class="highlight shell"&gt;&lt;code&gt;1 8,120,384,898 
2 1,9,1214,8827 
...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It turns out that generating a consistent row number like this is a difficult operation for Spark to handle. 
Matter of fact, it is probably an expensive task for any distributed system to perform. Also, 
I was working mostly with &lt;code&gt;Dataframes&lt;/code&gt; in Spark 2.0 and the only way that I know of currently to 
generate these row numbers is to first convert into an RDD and do a &lt;code&gt;zipWithIndex&lt;/code&gt; on it. &lt;/p&gt;
&lt;pre class="highlight scala"&gt;&lt;code&gt;&lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;segRdd&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;segmentIdGroups&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rdd&lt;/span&gt;
&lt;span class="k"&gt;val&lt;/span&gt; &lt;span class="n"&gt;rows&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="n"&gt;segRdd&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;zipWithIndex&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;map&lt;/span&gt; &lt;span class="o"&gt;{&lt;/span&gt; &lt;span class="k"&gt;case&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Row&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="k"&gt;:&lt;/span&gt; &lt;span class="kt"&gt;Long&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="k"&gt;=&amp;gt;&lt;/span&gt; &lt;span class="nc"&gt;Row&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;fromSeq&lt;/span&gt;&lt;span class="o"&gt;((&lt;/span&gt;&lt;span class="n"&gt;id&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+:&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;toSeq&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="o"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;Well, there is another method that involves windows and partitions but unfortunately it basically 
moves all the data into one partition, which isn&amp;rsquo;t feasible for me.&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Executer Cores and Memory Allocation&lt;/h3&gt;

&lt;p&gt;For the Spark task that I send to Amazon EMR, I manually set the 
&lt;code&gt;--executor-cores&lt;/code&gt; and &lt;code&gt;--executor-memory&lt;/code&gt; configurations. The calculation is somewhat 
non-intuitive because I had to manually take into account the overheads of &lt;code&gt;YARN&lt;/code&gt;, 
the application master/driver cores and memory usage et cetera.&lt;/p&gt;

&lt;p&gt;In general, YARN overheads take roughly &lt;code&gt;7%&lt;/code&gt; and reducing some from there is good practice, to ensure enough
is left for system processes and Hadoop e.g.&lt;/p&gt;

&lt;p&gt;Say for an instance of &lt;code&gt;r3.8xlarge&lt;/code&gt;&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;# 122GB RAM, 16 cores&lt;/span&gt;

&lt;span class="nv"&gt;$CORES_PER_DRIVER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;$MEMORY_PER_DRIVER&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;24G

&lt;span class="nv"&gt;$CORES_PER_EXECUTOR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;$MEMORY_PER_EXECUTOR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;24G
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;With 4 cores per executor, each instance could &lt;em&gt;potentially&lt;/em&gt; run 4 executors. To account for the overhead,
I multiply the memory by &lt;code&gt;93%&lt;/code&gt;, which works out to be &lt;code&gt;28G&lt;/code&gt;. In the end, I used &lt;code&gt;24G&lt;/code&gt; just 
to account for overheads for the driver, Hadoop processes, the UI and the OS but on hindsight, 
&lt;code&gt;26G&lt;/code&gt; probably would&amp;rsquo;ve worked too.&lt;/p&gt;
&lt;pre class="highlight scala"&gt;&lt;code&gt;&lt;span class="n"&gt;total_memory_available&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="n"&gt;total_cores_available&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mf"&gt;0.07&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;// 122GB/16 * (1 - 0.07) = 28G
// Leave some leeway, to 24-26G
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;em&gt;This directly affects how many executors that can be deployed per instance and also affects the
memory available for each task, and consequently for each shuffle operation.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: In the example above, 4 executors of 4 cores each will run on each instance of &lt;code&gt;r3.8xlarge&lt;/code&gt;.&lt;/p&gt;

&lt;h3&gt;Task / Partition Size&lt;/h3&gt;

&lt;p&gt;Another critical configuration is the task size; it is something that I think 
should be considered carefully because the task &lt;em&gt;will slow down&lt;/em&gt; by quite a bit if it starts to spill to disk.&lt;/p&gt;

&lt;p&gt;Initially, I just set the &lt;code&gt;default_parallelism&lt;/code&gt; in Spark and expected the system to automatically 
handle the rest, and was surprised to see some stages spilling to disk causing the cluster to slow down. 
I later found out that &lt;code&gt;default_parallelism&lt;/code&gt; is only used for certain operations and for the rest of the time, 
Spark would infer the size by looking at the input from a previous stage, which happens to be the number of files
it reads: 300. &lt;/p&gt;

&lt;p&gt;Each of these files are roughly 800-900MB. And having that few paritions is not ideal since 
each of these tasks / partitions will be too big to fit into memory. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Well alright, this actually depends on your executor setup too.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I had to force a repartition via &lt;code&gt;df.repartition(2000)&lt;/code&gt; right after the reading of the files. 
This would immediately add a shuffle step but performs better later on in other tasks in my opinion, YMMV though.&lt;/p&gt;

&lt;h3&gt;Shuffle Memory Usage, Executor Memory-to-CPU ratio&lt;/h3&gt;

&lt;p&gt;In general, I tried to optimize the system to avoid any form of spilling, both memory and disk. If
the entire shuffle operation can fit into memory, there will be no spilling.&lt;/p&gt;

&lt;p&gt;Each core in an executor runs a single task at any one time. Hence, with 26GB per executor and 4 cores each executor, 
the HEAP_SIZE allocated for each task is &lt;code&gt;26/4&lt;/code&gt; or &lt;code&gt;4G&lt;/code&gt;.  &lt;/p&gt;

&lt;p&gt;&lt;strong&gt;However, not all the memory allocated to the executor is used for shuffle operations.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The memory available for shuffle can be calculated as such:&lt;/p&gt;
&lt;pre class="highlight scala"&gt;&lt;code&gt;&lt;span class="c1"&gt;// Per task
&lt;/span&gt;&lt;span class="mi"&gt;24&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="mi"&gt;4&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.2&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="mf"&gt;0.8&lt;/span&gt; &lt;span class="k"&gt;=&lt;/span&gt; &lt;span class="mf"&gt;0.96&lt;/span&gt;&lt;span class="nc"&gt;GB&lt;/span&gt;

&lt;span class="c1"&gt;// 0.2 -&amp;gt; spark.shuffle.memoryFraction
// 0.8 -&amp;gt; spark.shuffle.safetyFraction
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your task is already spilling to disk, you can use this formula to find out how much space it
actually needs to better fine tune the RAM-to-CPU ratio for ur executor tasks.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;shuffle_write &lt;span class="k"&gt;*&lt;/span&gt; shuffle_spill_mem &lt;span class="k"&gt;*&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;4&lt;span class="o"&gt;)&lt;/span&gt;executor_cores
—————————————————————————————————————————————————————————————————————
shuffle_spill_disk &lt;span class="k"&gt;*&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;24&lt;span class="o"&gt;)&lt;/span&gt;executor_mem &lt;span class="k"&gt;*&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0.2&lt;span class="o"&gt;)&lt;/span&gt;shuffle_mem_fraction &lt;span class="k"&gt;*&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;0.8&lt;span class="o"&gt;)&lt;/span&gt;shuffle_safety_fraction
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Splitting the task size properly is probably one of the bigger improvements while tuning my cluster. 
&lt;strong&gt;Key takeaway:&lt;/strong&gt; It is definitely better to err on a higher number of partitions, which results in a smaller task bite size.&lt;/p&gt;

&lt;h3&gt;Counter Example&lt;/h3&gt;

&lt;p&gt;To quickly illustrate how things can go wrong in a problematic configuration, 
I&amp;rsquo;ll use one of my iterations as an example.&lt;/p&gt;

&lt;p&gt;I first used &lt;code&gt;c3&lt;/code&gt; &amp;amp; &lt;code&gt;m3&lt;/code&gt; instances and only allocated &lt;code&gt;10G&lt;/code&gt; per 3 cores. This works out
to be about 500MB for shuffling each task. I had only 300 partitions and my task sizes were well beyond 850MB. &lt;/p&gt;

&lt;p&gt;It resulted in a ton more needless computations:&lt;/p&gt;

&lt;p&gt;&lt;a href="https://s3-ap-southeast-1.amazonaws.com/homan/blog/spark-shuffle-spill.png"&gt;&lt;img src="https://s3-ap-southeast-1.amazonaws.com/homan/blog/spark-shuffle-spill-small.png" alt="Shuffle Spills" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3&gt;Getting the Right Partition Size and Instance Type&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;It is crucial to get the partition size right for it to run smoothly, but getting the right instance type
makes it much more efficient.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Back to my setup, with about 2000 paritions and 250GB data, each partition or task works out to be 
only about 125MB, which is close to the 128MB that is recommended in the official docs. &lt;/p&gt;

&lt;p&gt;At that partition size, it is more efficient to run &lt;code&gt;c3.8xlarge&lt;/code&gt; instances with 
a lower memory to core ratio. I did choose to use &lt;code&gt;i2.2xlarge&lt;/code&gt; memory instances to
eliminate any possibility of a memory constraint issue but the &lt;code&gt;c3.8xlarge&lt;/code&gt; would&amp;rsquo;ve been much faster.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;# c3.8xlarge: 32 VCPUS, 60GB Memory&lt;/span&gt;
&lt;span class="nv"&gt;$CORES_PER_EXECUTOR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;$MEMORY_PER_EXECUTOR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;6.5G

&lt;span class="c"&gt;# Available memory for shuffle, more than enough for 125mb&lt;/span&gt;
6.5 / 4 &lt;span class="k"&gt;*&lt;/span&gt; 0.2 &lt;span class="k"&gt;*&lt;/span&gt; 0.8 &lt;span class="o"&gt;=&lt;/span&gt; 0.26G
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Spot Instances and HDFS&lt;/h3&gt;

&lt;p&gt;Amazon EMR allows you to bid for spot instances at a &lt;em&gt;fraction of the cost&lt;/em&gt; of the original instance
price. I use them frequently and have found them to be massively discounted during some hours. &lt;/p&gt;

&lt;p&gt;I had HDFS running for the cluster and the results of each &lt;code&gt;result stage&lt;/code&gt; are stored into the HDFS for future use. 
At first, I ran a test using spot instances completely, even for the CORE instance group, which turned out to be
a big mistake.&lt;/p&gt;

&lt;p&gt;When I lose the instances, inevitably, from getting outbidded during peak hours, the cluster loses data. 
In my experience, Spark is unable to fully recover from the lost data, even after taking extra time for 
stage-retries.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;With everything taken into consideration, I found it easier to just use on-demand instances 
for the CORE instance group entirely.&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Instance Setup&lt;/h3&gt;

&lt;p&gt;I recommend using non-spot, disk-optimized instances for the CORE instance group. For example, I got two 800GB SSDs 
with an &lt;code&gt;i2.2xlarge&lt;/code&gt; which costs only ~$1.70 per hour. In comparison, &lt;code&gt;c3&lt;/code&gt; or &lt;code&gt;r3&lt;/code&gt; instances 
give you way lesser disk space.&lt;/p&gt;

&lt;p&gt;For the actual computation in the task instance group, I would switch to using only spot instances 
(&lt;code&gt;r3.8xlarge&lt;/code&gt; or &lt;code&gt;c3.8xlarge&lt;/code&gt;). I&amp;rsquo;ve found that this was the most cost-efficient to run my task.&lt;/p&gt;

&lt;p&gt;To bring it all together, I used 20 spot instances of &lt;code&gt;r3.8xlarge&lt;/code&gt;. Mentioned this above, but I&amp;rsquo;ll say it again.
Memory instances were used just to eliminate any potential issue of shuffle spills but &lt;code&gt;c3.8xlarge&lt;/code&gt; would&amp;rsquo;ve been more efficient
definitely as I&amp;rsquo;ve showned above. For the core group, there were 3 &lt;code&gt;i2.2xlarge&lt;/code&gt; on-demand instances for the HDFS.&lt;/p&gt;

&lt;h3&gt;To Persist or Not?&lt;/h3&gt;

&lt;p&gt;In some of the heavy shuffles, I found that it was faster to persist them on disk to 
prevent re-calculations. This is especially true if you&amp;rsquo;re re-using scala variables further
down the chain. Obviously, you&amp;rsquo;ll need to look into the total calculation time and compare it with
the network read bytes (divided by an average network throughput) to see if it is worth while to
persist. &lt;/p&gt;

&lt;p&gt;One good thing is that the Amazon EMR handles the HDFS integrations seamlessly which makes
it effortless to do a &lt;code&gt;DISK_ONLY&lt;/code&gt; persistance. One thing to note is that since I was doing some disk persistance, 
I do end up using more disk space than the total data size. This is also why I chose to use the &lt;code&gt;i2&lt;/code&gt; instances
for HDFS.&lt;/p&gt;

&lt;h3&gt;Recalculations vs Persistence&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;Recalculations will yield different sequences every time.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;In my case, having to generate a key for each row was the one requirement I couldn&amp;rsquo;t remove. &lt;/p&gt;

&lt;p&gt;Without persisting it to disk first, using the variable again would cause a re-calculation 
through the stages and &lt;code&gt;zipWithIndex&lt;/code&gt; could potentially produce results which are 
different each time and be rendered absolutely useless. &lt;/p&gt;

&lt;p&gt;I was forced to persist them to disk but either way, since they were heavy operations, persisting
them to disk made sense too.&lt;/p&gt;

&lt;h3&gt;Resources&lt;/h3&gt;

&lt;p&gt;All of the information has been sourced from multiple sources including, but not limited to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-2/"&gt;Cloudera, How to tune your Apache Spark Jobs Part 1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.cloudera.com/blog/2015/03/how-to-tune-your-apache-spark-jobs-part-1/"&gt;Cloudera, How to tune your Apache Spark Jobs Part 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gitbook.com/book/jaceklaskowski/mastering-apache-spark/details"&gt;Mastering Apache Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.linkedin.com/pulse/tune-spark-jobs-2-chaaranpall-lambba"&gt;Tune Spark Jobs 2&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.slideshare.net/cloudera/top-5-mistakes-to-avoid-when-writing-apache-spark-applications"&gt;Top 5 Mistakes while writing Apache Spark Applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</content>
  </entry>
  <entry>
    <title>How I Deployed My Golang Telegram Bot</title>
    <link rel="alternate" href="http://blog.url.com/posts/2017/01/21/how-i-deployed-golang-bot-on-digital-ocean/"/>
    <id>http://blog.url.com/posts/2017/01/21/how-i-deployed-golang-bot-on-digital-ocean/</id>
    <published>2017-01-21T00:00:00+08:00</published>
    <updated>2017-01-21T22:17:58+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;Continuing where I left off in the &lt;a href="https://aranair.github.io/posts/2016/12/25/how-to-set-up-golang-telegram-bot-with-webhooks/"&gt;first part&lt;/a&gt; of my &lt;code&gt;Golang Telegram Bot&lt;/code&gt;, in this post I go through all the
steps I took to get to a one command deployment of my Telegram bot into a Digital Ocean Ubuntu 16.04
instance. A number of components were involved: dockerizing the app, setting up a self-signed SSL cert,
get the Nginx to work as a reverse proxy with that, submitting the SSL to Telegram, and finally setting up
git post-update webhooks for deployment.&lt;/p&gt;

&lt;h3&gt;Dockerizing the App&lt;/h3&gt;

&lt;p&gt;To prepare the bot for deployment, a natural choice was to dockerize it. I&amp;rsquo;ve found it simpler, by far, to use docker 
to get the environment needed for my apps to run instead of manually fiddling with the server in most cases. It
also gives me the benefit of being able to run multiple containers on a single instance if the load
isn&amp;rsquo;t too high on them. Let&amp;rsquo;s dive in to the code.&lt;/p&gt;

&lt;h5&gt;Dockerfile&lt;/h5&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="s"&gt;FROM golang:1.6&lt;/span&gt;

&lt;span class="s"&gt;ADD configs.toml /go/bin/&lt;/span&gt;

&lt;span class="s"&gt;ADD . /go/src/github.com/aranair/remindbot&lt;/span&gt;
&lt;span class="s"&gt;WORKDIR /go/src/github.com/aranair/remindbot&lt;/span&gt;

&lt;span class="s"&gt;RUN go get ./...&lt;/span&gt;
&lt;span class="s"&gt;RUN go install ./...&lt;/span&gt;

&lt;span class="s"&gt;WORKDIR /go/bin/&lt;/span&gt;
&lt;span class="s"&gt;ENTRYPOINT remindbot&lt;/span&gt;

&lt;span class="s"&gt;EXPOSE 8080&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I start from the base &lt;a href="https://github.com/docker-library/golang/blob/master/1.6/Dockerfile"&gt;Golang 1.6 image&lt;/a&gt;. &lt;/p&gt;

&lt;p&gt;From there, the next line adds a &lt;code&gt;configs.toml&lt;/code&gt; into the bin folder.
This file contains credentials and configs that my app needs to run. This should be added into the server
manually, so that it doesn&amp;rsquo;t get checked into the github repository for security reasons. &lt;/p&gt;

&lt;p&gt;I took a look at the &lt;a href="https://github.com/docker-library/golang/blob/master/1.6/Dockerfile"&gt;official Golang Dockerfile&lt;/a&gt; and I saw that the default &lt;code&gt;gopath&lt;/code&gt; is &lt;code&gt;/go&lt;/code&gt;.
By adding my config item into &lt;code&gt;/go/bin&lt;/code&gt; folder, I can easily give the app direct access to the file,
without having to provide it an additional arbiturary path to get that file.&lt;/p&gt;

&lt;p&gt;The next line adds the files into the image during the build process.
Previously, I would get the files in a different way. I would use this:&lt;/p&gt;
&lt;pre class="highlight docker"&gt;&lt;code&gt;go get /go/src/github.com/aranair/remindbot
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;But it&amp;rsquo;s actually a little easier to do it in the above way:&lt;/p&gt;
&lt;pre class="highlight docker"&gt;&lt;code&gt;&lt;span class="k"&gt;ADD&lt;/span&gt;&lt;span class="s"&gt; . /go/src/github.com/aranair/remindbot&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This would take all the files at &lt;code&gt;.&lt;/code&gt;, the location where &lt;code&gt;docker build&lt;/code&gt; 
would run from, and copy them  into &lt;code&gt;/go/src/github.com/aranair/remindbot&lt;/code&gt; during the build process, 
essentially achieving the same result as &lt;code&gt;go get ...&lt;/code&gt;. &lt;/p&gt;

&lt;p&gt;What&amp;rsquo;s different here is that I don&amp;rsquo;t -have- to remember to push to github before the deployment. 
I also wouldn&amp;rsquo;t need to manually &lt;code&gt;git pull&lt;/code&gt;. The entire deployment process can be contained 
inside the post-update webhook. I&amp;rsquo;ll discuss that in more detail further down.&lt;/p&gt;

&lt;h3&gt;Docker Compose&lt;/h3&gt;

&lt;p&gt;Personally, I hate fiddling with manual running of the containers so I just use docker-compose, 
especially if there is more than one component to worry about. For this bot, there is really only
the mounted volume so that my sqlite3 files won&amp;rsquo;t get flushed on a deployment but I could 
just as easily set-up a PostgreSQL database up with a few simple additions to this file.&lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="na"&gt;version&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s1"&gt;'&lt;/span&gt;&lt;span class="s"&gt;2'&lt;/span&gt;
&lt;span class="na"&gt;services&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;gobot&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
    &lt;span class="na"&gt;build&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;.&lt;/span&gt;
    &lt;span class="na"&gt;ports&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="s"&gt;8080:8080"&lt;/span&gt;
    &lt;span class="na"&gt;volumes&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;/var/data:/var/data&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The section under ports exposes and links the container&amp;rsquo;s port 8080 to the server&amp;rsquo;s port 8080 (&lt;code&gt;HOST::CONTAINER&lt;/code&gt; format). 
More about that can be found in the &lt;a href="https://docs.docker.com/compose/compose-file/#/ports"&gt;compose-file documentations&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;For the volumes, the code above simply tells the container to link the host&amp;rsquo;s &lt;code&gt;/var/data/&lt;/code&gt; to the container&amp;rsquo;s &lt;code&gt;/var/data/&lt;/code&gt;
essentially creating a mounted volume. Again, the format is &lt;code&gt;HOST::CONTAINER&lt;/code&gt;. I store the files there for my 
&lt;code&gt;Sqlite&lt;/code&gt; database and this mounted volume preserves the data on deployments.&lt;/p&gt;

&lt;h3&gt;How to Set-up Self-Signed SSL Certificate&lt;/h3&gt;

&lt;p&gt;One of the main hassles and requirements of the Telegram API is that they require https, and that requires
an SSL certificate. It encrypts communication between Telegram and my server, and this helps Telegram to
verify that my server is the correct one, and not a bogus one when a potential man-in-the-middle hijacks the 
traffic.&lt;/p&gt;

&lt;p&gt;I could go get an SSL cert from a provider, but in this case, what we&amp;rsquo;re really concerned is the
identity of my server to Telegram and not for users so a self-signed certificate would work just as well.&lt;/p&gt;

&lt;p&gt;I SSH&amp;rsquo;d into the server to create the certs.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;sudo openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/ssl/private/self-signed.key -out /etc/ssl/certs/self-signed.crt
&lt;/code&gt;&lt;/pre&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-days&lt;/code&gt; defines the validity span. I did adjust the validity-days to something much bigger but generally might be better with a year or two.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rsa:2048&lt;/code&gt; means that will create an RSA key that is 2048 bits long.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-keyout&lt;/code&gt; refers to the private key for the cert&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-out&lt;/code&gt; refers the cert itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The process leads me through the steps above for some further information. The most important bit
is the &lt;strong&gt;Common Name&lt;/strong&gt;. In my case, I didn&amp;rsquo;t have a domain, so I simply put in the &lt;code&gt;server_IP_address&lt;/code&gt; 
for my Digital Ocean instance.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;Country Name (2 letter code) [AU]:SG
State or Province Name (full name) [Some-State]:Singapore
Locality Name (eg, city) []:Singapore
Organization Name (eg, company) [Internet Widgits Pty Ltd]:
Organizational Unit Name (eg, section) []:
Common Name (e.g. server FQDN or YOUR name) []:server_IP_address
Email Address []:boa.homan@gmail.com
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;As part of Nginx best practices, I also created a strong Diffie-Hellman group for added security.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;sudo openssl dhparam -out /etc/nginx/ssl/dhparam.pem 2048
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Configuring Nginx to Use the SSL Cert&lt;/h3&gt;

&lt;p&gt;I first made a new Nginx configuration snippet at &lt;code&gt;/etc/nginx/snippets&lt;/code&gt; that simply points
to the SSL certs I just created above.&lt;/p&gt;
&lt;pre class="highlight conf"&gt;&lt;code&gt;&lt;span class="n"&gt;ssl_certificate&lt;/span&gt; /&lt;span class="n"&gt;etc&lt;/span&gt;/&lt;span class="n"&gt;ssl&lt;/span&gt;/&lt;span class="n"&gt;certs&lt;/span&gt;/&lt;span class="n"&gt;self&lt;/span&gt;-&lt;span class="n"&gt;signed&lt;/span&gt;.&lt;span class="n"&gt;crt&lt;/span&gt;;
&lt;span class="n"&gt;ssl_certificate_key&lt;/span&gt; /&lt;span class="n"&gt;etc&lt;/span&gt;/&lt;span class="n"&gt;ssl&lt;/span&gt;/&lt;span class="n"&gt;private&lt;/span&gt;/&lt;span class="n"&gt;self&lt;/span&gt;-&lt;span class="n"&gt;signed&lt;/span&gt;.&lt;span class="n"&gt;key&lt;/span&gt;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Another snippet to set-up some SSL settings based on recommendations from &lt;a href="https://cipherli.st/"&gt;https://cipherli.st/&lt;/a&gt;.&lt;/p&gt;
&lt;pre class="highlight conf"&gt;&lt;code&gt;&lt;span class="c"&gt;# from https://cipherli.st/
# and https://raymii.org/s/tutorials/Strong_SSL_Security_On_nginx.html
&lt;/span&gt;
&lt;span class="n"&gt;ssl_protocols&lt;/span&gt; &lt;span class="n"&gt;TLSv1&lt;/span&gt; &lt;span class="n"&gt;TLSv1&lt;/span&gt;.&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="n"&gt;TLSv1&lt;/span&gt;.&lt;span class="m"&gt;2&lt;/span&gt;;
&lt;span class="n"&gt;ssl_prefer_server_ciphers&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;;
&lt;span class="n"&gt;ssl_ciphers&lt;/span&gt; &lt;span class="s2"&gt;"EECDH+AESGCM:EDH+AESGCM:AES256+EECDH:AES256+EDH"&lt;/span&gt;;
&lt;span class="n"&gt;ssl_ecdh_curve&lt;/span&gt; &lt;span class="n"&gt;secp384r1&lt;/span&gt;;
&lt;span class="n"&gt;ssl_session_cache&lt;/span&gt; &lt;span class="n"&gt;shared&lt;/span&gt;:&lt;span class="n"&gt;SSL&lt;/span&gt;:&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="n"&gt;m&lt;/span&gt;;
&lt;span class="n"&gt;ssl_session_tickets&lt;/span&gt; &lt;span class="n"&gt;off&lt;/span&gt;;
&lt;span class="n"&gt;ssl_stapling&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;;
&lt;span class="n"&gt;ssl_stapling_verify&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt;;
&lt;span class="n"&gt;resolver&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;.&lt;span class="m"&gt;8&lt;/span&gt;.&lt;span class="m"&gt;8&lt;/span&gt;.&lt;span class="m"&gt;8&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;.&lt;span class="m"&gt;8&lt;/span&gt;.&lt;span class="m"&gt;4&lt;/span&gt;.&lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="n"&gt;valid&lt;/span&gt;=&lt;span class="m"&gt;300&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;;
&lt;span class="n"&gt;resolver_timeout&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;;
&lt;span class="c"&gt;# Disable preloading HSTS for now.  You can use the commented out header line that includes
# the "preload" directive if you understand the implications.
#add_header Strict-Transport-Security "max-age=63072000; includeSubdomains; preload";
&lt;/span&gt;&lt;span class="n"&gt;add_header&lt;/span&gt; &lt;span class="n"&gt;Strict&lt;/span&gt;-&lt;span class="n"&gt;Transport&lt;/span&gt;-&lt;span class="n"&gt;Security&lt;/span&gt; &lt;span class="s2"&gt;"max-age=63072000; includeSubdomains"&lt;/span&gt;;
&lt;span class="n"&gt;add_header&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;-&lt;span class="n"&gt;Frame&lt;/span&gt;-&lt;span class="n"&gt;Options&lt;/span&gt; &lt;span class="n"&gt;DENY&lt;/span&gt;;
&lt;span class="n"&gt;add_header&lt;/span&gt; &lt;span class="n"&gt;X&lt;/span&gt;-&lt;span class="n"&gt;Content&lt;/span&gt;-&lt;span class="n"&gt;Type&lt;/span&gt;-&lt;span class="n"&gt;Options&lt;/span&gt; &lt;span class="n"&gt;nosniff&lt;/span&gt;;

&lt;span class="n"&gt;ssl_dhparam&lt;/span&gt; /&lt;span class="n"&gt;etc&lt;/span&gt;/&lt;span class="n"&gt;ssl&lt;/span&gt;/&lt;span class="n"&gt;certs&lt;/span&gt;/&lt;span class="n"&gt;dhparam&lt;/span&gt;.&lt;span class="n"&gt;pem&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Finally, we will need to edit the Nginx configuration files to use SSL.&lt;/p&gt;

&lt;p&gt;This is what the file intially looks like: &lt;/p&gt;
&lt;pre class="highlight conf"&gt;&lt;code&gt;&lt;span class="c"&gt;# /etc/nginx/sites-available/default
&lt;/span&gt;
&lt;span class="n"&gt;server&lt;/span&gt; {
    &lt;span class="n"&gt;listen&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;
    &lt;span class="n"&gt;listen&lt;/span&gt; [::]:&lt;span class="m"&gt;80&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;

    &lt;span class="c"&gt;# SSL configuration
&lt;/span&gt;
    &lt;span class="c"&gt;# listen 443 ssl default_server;
&lt;/span&gt;    &lt;span class="c"&gt;# listen [::]:443 ssl default_server;
&lt;/span&gt;
    ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;I changed it to look like this (remember to replace IP!)&lt;/p&gt;
&lt;pre class="highlight conf"&gt;&lt;code&gt;&lt;span class="n"&gt;server&lt;/span&gt; {
  &lt;span class="n"&gt;listen&lt;/span&gt; &lt;span class="m"&gt;80&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;
  &lt;span class="n"&gt;listen&lt;/span&gt; [::]:&lt;span class="m"&gt;80&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;
  &lt;span class="n"&gt;server_name&lt;/span&gt; &lt;span class="n"&gt;YOUR_SERVER_IP_ADDRESS&lt;/span&gt;;
  &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="m"&gt;301&lt;/span&gt; &lt;span class="n"&gt;https&lt;/span&gt;://$&lt;span class="n"&gt;server_name&lt;/span&gt;$&lt;span class="n"&gt;request_uri&lt;/span&gt;;
}

&lt;span class="n"&gt;server&lt;/span&gt; {
&lt;span class="c"&gt;# SSL configuration
&lt;/span&gt;
  &lt;span class="n"&gt;listen&lt;/span&gt; &lt;span class="m"&gt;443&lt;/span&gt; &lt;span class="n"&gt;ssl&lt;/span&gt; &lt;span class="n"&gt;http2&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;
  &lt;span class="n"&gt;listen&lt;/span&gt; [::]:&lt;span class="m"&gt;443&lt;/span&gt; &lt;span class="n"&gt;ssl&lt;/span&gt; &lt;span class="n"&gt;http2&lt;/span&gt; &lt;span class="n"&gt;default_server&lt;/span&gt;;

  &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="n"&gt;snippets&lt;/span&gt;/&lt;span class="n"&gt;self&lt;/span&gt;-&lt;span class="n"&gt;signed&lt;/span&gt;.&lt;span class="n"&gt;conf&lt;/span&gt;;
  &lt;span class="n"&gt;include&lt;/span&gt; &lt;span class="n"&gt;snippets&lt;/span&gt;/&lt;span class="n"&gt;ssl&lt;/span&gt;-&lt;span class="n"&gt;params&lt;/span&gt;.&lt;span class="n"&gt;conf&lt;/span&gt;;

  &lt;span class="n"&gt;location&lt;/span&gt; / {
    &lt;span class="n"&gt;proxy_pass&lt;/span&gt; &lt;span class="n"&gt;http&lt;/span&gt;://&lt;span class="m"&gt;127&lt;/span&gt;.&lt;span class="m"&gt;0&lt;/span&gt;.&lt;span class="m"&gt;0&lt;/span&gt;.&lt;span class="m"&gt;1&lt;/span&gt;:&lt;span class="m"&gt;8080&lt;/span&gt;;
  }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What I did was to basically ask Nginx to automatically redirect HTTP requests to HTTPS. And ask it to
server root from the port 8080 that the docker container is listening to.&lt;/p&gt;

&lt;h3&gt;UFW Firewall&lt;/h3&gt;

&lt;p&gt;For security reasons, I also enabled &lt;a href="https://help.ubuntu.com/community/UFW"&gt;ufw firewall&lt;/a&gt; by doing the following: &lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;sudo ufw &lt;span class="nb"&gt;enable
&lt;/span&gt;sudo ufw allow &lt;span class="s1"&gt;'OpenSSH'&lt;/span&gt;
sudo ufw allow &lt;span class="s1"&gt;'Nginx Full'&lt;/span&gt;
sudo ufw delete allow &lt;span class="s1"&gt;'Nginx HTTP'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It should look something like this in &lt;code&gt;sudo ufw status&lt;/code&gt;&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;To                         Action      From
--                         ------      ----
Nginx Full                 ALLOW       Anywhere
OpenSSH                    ALLOW       Anywhere
Nginx Full &lt;span class="o"&gt;(&lt;/span&gt;v6&lt;span class="o"&gt;)&lt;/span&gt;            ALLOW       Anywhere &lt;span class="o"&gt;(&lt;/span&gt;v6&lt;span class="o"&gt;)&lt;/span&gt;
OpenSSH &lt;span class="o"&gt;(&lt;/span&gt;v6&lt;span class="o"&gt;)&lt;/span&gt;               ALLOW       Anywhere &lt;span class="o"&gt;(&lt;/span&gt;v6&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And its done; to start Nginx, all that&amp;rsquo;s left is to &lt;code&gt;sudo nginx -t&lt;/code&gt;&lt;/p&gt;

&lt;h3&gt;Sending Telegram the SSL Cert&lt;/h3&gt;

&lt;p&gt;Telegram will need the other side of the cert. Consulting their documentation, it seems that they
need the PEM file. To get that, I had to convert the current CRT file into the PEM format.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;openssl x509 -in /etc/ssl/certs/self-signed.crt -outform pem -out /etc/ssl/certs/bot.pem
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To get the cert to Telegram&amp;rsquo;s hands, I sent it via their API using this: (Replace bot keys!)&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;curl -F &lt;span class="s2"&gt;"url=https://your.domain.or.ip.com"&lt;/span&gt; -F &lt;span class="s2"&gt;"certificate=@/etc/ssl/certs/bot.pem"&lt;/span&gt; https://api.telegram.org/bot12345:ABC-DEF1234ghIkl-zyx57W2v1u123ew11/setWebhook
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Set-up Git Hooks&lt;/h3&gt;

&lt;p&gt;Great! Now all that&amp;rsquo;s left is the deployment process. The general outcome that I wanted is that
it&amp;rsquo;ll be a one-command process that updates the code in the server, rebuilds and restarts the docker
container with the updated app.&lt;/p&gt;

&lt;p&gt;At my server, I created the necessary files for the server git repository&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="nb"&gt;cd&lt;/span&gt; /var
mkdir repo &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd &lt;/span&gt;repo
mkdir bot.git &lt;span class="o"&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class="nb"&gt;cd &lt;/span&gt;bot.git
git init --bare
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;The Hooks&lt;/h4&gt;

&lt;p&gt;Looking into the &lt;code&gt;hooks&lt;/code&gt; folder in bot.git, there were many samples for the different hooks provided.
For the purpose of this bot, I created a &lt;code&gt;post-receive&lt;/code&gt; hook with the following content.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;#!/bin/sh&lt;/span&gt;
git --work-tree&lt;span class="o"&gt;=&lt;/span&gt;/var/app/remindbot --git-dir&lt;span class="o"&gt;=&lt;/span&gt;/var/repo/bot.git checkout -f
&lt;span class="nb"&gt;cd&lt;/span&gt; /var/app/remindbot
docker-compose build
docker-compose down
docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The sets the &lt;code&gt;/var/app&lt;/code&gt; folder to be the working directory for my app. And the script goes into
my working directory and rebuilds the container and restarts it. All of this will happen on deployment!&lt;/p&gt;

&lt;p&gt;Of course, I also had to make the post-receive file executable.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;chmod +x post-receive
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Deploy All The Things!&lt;/h3&gt;

&lt;p&gt;From my development machine, I added a remote repo to my local git repo.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;git remote add prod ssh://user@my.domain.or.ip.com/var/repo/bot.git
git push prod master
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And the Telegram bot finally goes live, responding to live chats in Telegram. All of this code can be found 
at the &lt;a href="https://github.com/aranair/remindbot"&gt;project github repository&lt;/a&gt;. The reminder bot&amp;rsquo;s name is Hazel. She responds instantly to 
chats in Telegram and helps me to manage my ever-growing list of responsibilities everyday now :P&lt;/p&gt;

&lt;p&gt;Feel free to star it or fork it or leave comments below!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>How I Built a Simple Telegram Bot in Go</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/12/25/how-to-set-up-golang-telegram-bot-with-webhooks/"/>
    <id>http://blog.url.com/posts/2016/12/25/how-to-set-up-golang-telegram-bot-with-webhooks/</id>
    <published>2016-12-25T00:00:00+08:00</published>
    <updated>2017-01-21T17:41:06+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;This is the first part of the &lt;code&gt;Golang Telegram Bot&lt;/code&gt; series. 
In this series, I&amp;rsquo;ll show you, with code samples, how I built a Golang Telegram Bot for my own use. 
It would listen in and respond in real-time to certain text cues. 
Finally I&amp;rsquo;ll also show you how to get a self-signed SSL cert working with Nginx
and deploying the application in a Docker container on a Digital Ocean instance.&lt;/p&gt;

&lt;p&gt;Hopefully this will help anyone out there who would like to try their hand at their own bot on Telegram!
The code for this bot is currently hosted at &lt;a href="https://github.com/aranair/remindbot"&gt;https://github.com/aranair/remindbot&lt;/a&gt; if you&amp;rsquo;ll like
to just skip to the code immediately.&lt;/p&gt;

&lt;h3&gt;Backstory&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve been using &lt;a href="https://web.telegram.org"&gt;Telegram&lt;/a&gt; for a really long time, and been wanting to build a Telegram bot 
for a long time since they first announced it. &lt;/p&gt;

&lt;p&gt;Initially, I was thrown off a little by the requirement of https for the webhooks, 
thinking that I might need a domain and a SSL cert to get it working but I quickly found out that
a self-signed SSL certificate would work just as well in this scenario!&lt;/p&gt;

&lt;p&gt;So, if you find yourself in the same situation, don&amp;rsquo;t worry about it! It might be slightly more complex 
to set up a self-signed SSL cert with Nginx, but it&amp;rsquo;s not that difficult! In this series, I&amp;rsquo;ll show you the code
samples that got my own bot up and running in production!&lt;/p&gt;

&lt;h3&gt;Creating a Bot and Getting an API Key&lt;/h3&gt;

&lt;p&gt;First, I sent &lt;code&gt;/newbot&lt;/code&gt; to this guy.&lt;/p&gt;

&lt;p&gt;&lt;a href="https://telegram.me/botfather"&gt;&lt;img src="https://s24.postimg.org/d0amvsmut/botfather.png" alt="botfather.png" /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;After creating the bot, I got a set of (botId and API key) by sending him a &lt;code&gt;/token&lt;/code&gt; command.&lt;br&gt;
The credentials are needed for subsequent requests to execute methods using the Telegram API. &lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="c1"&gt;# {botId}:{apiKey}&lt;/span&gt;
&lt;span class="s"&gt;123456:ABC-DEF1234ghIkl-zyx57W2v1u123ew11&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Take note&lt;/strong&gt; of the word &lt;code&gt;bot&lt;/code&gt; before the &lt;code&gt;&amp;lt;token&amp;gt;&lt;/code&gt;!&lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="s"&gt;https://api.telegram.org/bot&amp;lt;token&amp;gt;/METHOD_NAME&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;There are a ton of Api methods listed over at the &lt;a href="https://core.telegram.org/bots/api#available-methods"&gt;Telegram Bot docs&lt;/a&gt; but for the purpose
of this simple starter bot, I will only be using &lt;a href="https://core.telegram.org/bots/api#setwebhook"&gt;setWebhook&lt;/a&gt; and &lt;a href="https://core.telegram.org/bots/api#sendMessage"&gt;sendMessage&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;Webhook vs Polling&lt;/h3&gt;

&lt;p&gt;Great! I have the API key now. Next, I have to choose between the two ways to get messages from Telegram.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Webhooks via &lt;code&gt;setWebhook&lt;/code&gt; or&lt;/li&gt;
&lt;li&gt;Polling via &lt;code&gt;getUpdates&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I&amp;rsquo;m fairly certain that it is easier to set up with &lt;code&gt;getUpdates&lt;/code&gt; but polling isn&amp;rsquo;t always an option and not having
real-time updates isn&amp;rsquo;t as fun IMHO :P So, for this bot, I went with webhooks as I wanted the bot to respond in real-time.&lt;/p&gt;

&lt;p&gt;With webhooks, everytime there is a message (when privacy mode is disabled anyway), the API endpoint
will be sent a message. So the main objective, is simply, to parse each of these updates and respond appropriately.&lt;/p&gt;

&lt;p&gt;To set up the Webhook all I had to do is to send a curl request to the Telegram Api.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;curl -F &lt;span class="s2"&gt;"url=https://your.domain.com"&lt;/span&gt; -F &lt;span class="s2"&gt;"certificate=@/file/path/ssl/bot.pem"&lt;/span&gt; https://api.telegram.org/bot12345:ABC-DEF1234ghIkl-zyx57W2v1u123ew11/setWebhook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Of course, before that, I need the self-signed SSL &lt;strong&gt;public&lt;/strong&gt; pem file; that is sent as an &lt;code&gt;InputFile&lt;/code&gt; so that
Telegram can differentiate the correct server it&amp;rsquo;s supposed to send all the messages to. This part is a bit more relevant
in the second part of the series where I deploy the bot to Digital Ocean so I&amp;rsquo;ll leave this explanation to the second part.&lt;/p&gt;

&lt;h3&gt;Router&lt;/h3&gt;

&lt;p&gt;I had a choice of many popular router implementations out there like &lt;a href="https://github.com/gin-gonic/gin"&gt;gin&lt;/a&gt; and &lt;a href="https://github.com/gorilla/context"&gt;gorilla&lt;/a&gt;.
But for this project, I chose to go a bit ligher with just &lt;code&gt;github.com/gorilla/context&lt;/code&gt; and 
&lt;code&gt;github.com/julienschmidt/httprouter&lt;/code&gt; since I don&amp;rsquo;t really need that much functionality.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Ok, to be fair, even the context (for the params) isn&amp;rsquo;t really needed at this point, but
since I would need them for get requests in future, I&amp;rsquo;ve set it all up first.&lt;/em&gt;&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;package&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;import&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="s"&gt;"net/http"&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="s"&gt;"github.com/gorilla/context"&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="s"&gt;"github.com/julienschmidt/httprouter"&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;httprouter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Router&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;httprouter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;POST&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Handle&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"POST"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;wrapHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;wrapHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Handler&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;httprouter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Handle&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ResponseWriter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;httprouter&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Params&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;context&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Set&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"params"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;ps&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;h&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ServeHTTP&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Configs&lt;/h3&gt;

&lt;p&gt;To parse the config toml file, I used &lt;code&gt;github.com/BurntSushi/toml&lt;/code&gt; with &lt;code&gt;toml&lt;/code&gt; files. It&amp;rsquo;s like &lt;code&gt;yml&lt;/code&gt; on steroids lol.&lt;/p&gt;

&lt;p&gt;The &lt;code&gt;datapath&lt;/code&gt; is actually the data volume path for Docker; but I&amp;rsquo;ll talk about that in more details in the second part 
of this series about deployments.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sample configs.toml&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;bot&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="x"&gt;
  &lt;/span&gt;&lt;span class="n"&gt;bot_id&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"YOUR_BOT_ID"&lt;/span&gt;&lt;span class="x"&gt;
  &lt;/span&gt;&lt;span class="n"&gt;api_key&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"YOUR_API_KEY"&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;database&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="x"&gt;
  &lt;/span&gt;&lt;span class="n"&gt;datapath&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"PATH_TO_SQLITEE_FOLDER"&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;App Context / Http Handlers Glue&lt;/h3&gt;

&lt;p&gt;Instead of a global object, I mixed app-wide objects like configs and the DB object into an &lt;code&gt;AppContext&lt;/code&gt;.
To link the &lt;code&gt;AppContext&lt;/code&gt; and the &lt;code&gt;http handlers&lt;/code&gt; together, I used &lt;a href="https://github.com/justinas/alice"&gt;github.com/justinas/alice&lt;/a&gt; as the glue.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;App Context&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DB&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;cmds&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;commands&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;NewAppContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DB&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;config&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Config&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmds&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;commands&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmds&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;cmds&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Message Receiver&lt;/strong&gt;:&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;CommandHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ResponseWriter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Main&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Since this bot was mainly built for personal reminders, I&amp;rsquo;ve chosen to go with &lt;code&gt;Sqlite3&lt;/code&gt; for now but I&amp;rsquo;ve 
got it set up with &lt;code&gt;pq&lt;/code&gt; before and it is fairly easy to swap it out, since both the libraries uses the &lt;code&gt;database/sql&lt;/code&gt; 
library.&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;toml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DecodeFile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"configs.toml"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;sql&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"sqlite3"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;DB&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Datapath&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;"/reminders.db"&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="n"&gt;checkErr&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;handlers&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NewAppContext&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;db&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;commands&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NewCommandList&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;alice&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;router&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;New&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;POST&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;"/reminders"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;stack&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ThenFunc&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;CommandHandler&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ListenAndServe&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;":8080"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Parsing the Updates&lt;/h3&gt;

&lt;p&gt;The updates that Telegram sends to the bot contains a lot of fields, including some optional ones 
that may or may not appear depending on the type of update, but the ones I&amp;rsquo;m concerned with for
this bot are only these:&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Update&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Id&lt;/span&gt;&lt;span class="x"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;int64&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="s"&gt;`json:"update_id"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Msg&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Message&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;`json:"message"`&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Message&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Id&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="kt"&gt;int64&lt;/span&gt;&lt;span class="x"&gt;  &lt;/span&gt;&lt;span class="s"&gt;`json:"message_id"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;`json:"text"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Chat&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Chat&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="s"&gt;`json:"chat"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="s"&gt;`json:"from"`&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Note&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;this&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;is&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;an&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;optional&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;field&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;so&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;it&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;may&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;be&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;empty&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Chat&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Id&lt;/span&gt;&lt;span class="x"&gt;    &lt;/span&gt;&lt;span class="kt"&gt;int64&lt;/span&gt;&lt;span class="x"&gt;  &lt;/span&gt;&lt;span class="s"&gt;`json:"id"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Title&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;`json:"title"`&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;User&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Id&lt;/span&gt;&lt;span class="x"&gt;        &lt;/span&gt;&lt;span class="kt"&gt;int64&lt;/span&gt;&lt;span class="x"&gt;  &lt;/span&gt;&lt;span class="s"&gt;`json:"id"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;FirstName&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;`json:"first_name"`&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;Username&lt;/span&gt;&lt;span class="x"&gt;  &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;`json:"username"`&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="err"&gt;#&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Note&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;another&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;optional&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;field&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Updates comes in as &lt;code&gt;JSON&lt;/code&gt; and you can use the code snippet below with the structs above to decode it
into a more usable object.&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;CommandHandler&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;w&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ResponseWriter&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Update&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;NewDecoder&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Body&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;decoder&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Decode&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;&amp;amp;&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;!=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="no"&gt;nil&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;err&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;log&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Println&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;txt&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;cmds&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;chatId&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;update&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Msg&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Chat&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Id&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="k"&gt;switch&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ToLower&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cmd&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
      &lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;Some key things to note here:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The message is parsed into &lt;code&gt;update.Msg.Text&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;chatId&lt;/code&gt; is in &lt;code&gt;update.Msg.Chat.Id&lt;/code&gt;. This is important because you&amp;rsquo;ll need it to send a 
response back.&lt;/li&gt;
&lt;li&gt;The bot currently doesn&amp;rsquo;t use &lt;code&gt;User&lt;/code&gt; but I&amp;rsquo;ve written the code above so that you can get it as well.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Command Extraction&lt;/h3&gt;

&lt;p&gt;There is a &lt;code&gt;Commands&lt;/code&gt; object that contains all the &lt;code&gt;regexp.Regexp&lt;/code&gt; items that are used to find matches 
for commands. These are instantiated once during bot startup but I admit this part is a lot more 
repetitive than needed and I am still looking for ways to clean this up.&lt;/p&gt;

&lt;p&gt;So if you have any suggestions, do let me know in the comments below!&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;package&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;commands&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;import&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"regexp"&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;type&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="k"&gt;struct&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;rmt&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="x"&gt;    &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;hazel&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;NewCommandList&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;rmt&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt;   &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)^(remind) me to (.+)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)^(remind) (.+)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;l&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)^(list)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt;     &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)^(clear) (\d+)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;cl&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt;    &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)^(clearall)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="n"&gt;hazel&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;`(?i)(hazel)`&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;compileRegexp&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Regexp&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;regexp&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

&lt;/span&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;Commands&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;Extract&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;var&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;[]&lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;c&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;rmt&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FindStringSubmatch&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="k"&gt;if&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
        &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;a&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="k"&gt;return&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;""&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;strong&gt;A couple of comments for the code above:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;(?i)&lt;/code&gt; is there for case-insensitive regexp.&lt;/li&gt;
&lt;li&gt;I parse the commands and return the command and messages separately back to the route handler for 
it to do more there.&lt;/li&gt;
&lt;li&gt;If it doesn&amp;rsquo;t match, it&amp;rsquo;ll just return empty strings and subsequently gets thrown away.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;Sending a Response&lt;/h3&gt;

&lt;p&gt;I can send either a &lt;code&gt;GET&lt;/code&gt; or a &lt;code&gt;POST&lt;/code&gt; request to the appropriate API. I used the &lt;code&gt;sendMessage&lt;/code&gt; method via the API.
The text in this case, can contain codes like &lt;code&gt;\n&lt;/code&gt; and Unicode like &lt;code&gt;안녕&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;To replace the botId, apiKey, chatId and text for the &lt;code&gt;GET&lt;/code&gt; request, I do the following:&lt;/p&gt;
&lt;pre class="highlight go"&gt;&lt;code&gt;&lt;span class="k"&gt;func&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="n"&gt;AppContext&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;sendText&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;chatId&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;int64&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="kt"&gt;string&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"https://api.telegram.org/bot{botId}:{apiKey}/sendMessage?chat_id={chatId}&amp;amp;text={text}"&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{botId}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BOT&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BotId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{apiKey}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;ac&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;conf&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;BOT&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;ApiKey&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{chatId}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;strconv&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;FormatInt&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;chatId&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
    &lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;s&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Replace&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="s"&gt;"{text}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;QueryEscape&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;

    &lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;_&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="x"&gt; &lt;/span&gt;&lt;span class="n"&gt;http&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;link&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="x"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And it&amp;rsquo;s done! The application code is pretty short I&amp;rsquo;ll say.&lt;/p&gt;

&lt;h3&gt;To Be Continued&lt;/h3&gt;

&lt;p&gt;I hope this gives you a rough idea if you would like to get started in writing the application code for a Telegram Bot.&lt;/p&gt;

&lt;p&gt;In Part 2, I will talk about how I set up &lt;code&gt;Docker&lt;/code&gt; for the bot, and also
the self-signed SSL cert with Nginx as the reverse proxy on a Digital Ocean instance. Finally, 
I&amp;rsquo;ll also show how I set up the git webhooks so that I can deploy with just one command!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>Preventing Duplicates: Amazon EMR Pig to Elasticsearch</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/12/24/prevent-aws-emr-pig-elasticsearch-duplicates/"/>
    <id>http://blog.url.com/posts/2016/12/24/prevent-aws-emr-pig-elasticsearch-duplicates/</id>
    <published>2016-12-24T00:00:00+08:00</published>
    <updated>2016-12-25T21:19:25+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In the &lt;a href="https://aranair.github.io/posts/2016/12/14/aws-emr-pig-index-into-elasticsearch/"&gt;previous post&lt;/a&gt;, I went through some steps I took to set up the Amazon EMR Hadoop cluster
to run Apache Pig scripts for indexing data to Elasticsearch. In today&amp;rsquo;s series, I walk through some of the
problems I encountered when I set the system up and some of the configuration tweaks to both
Elasticsearch and the EMR cluster that I feel you should consciously think about if you&amp;rsquo;re looking 
to set it up in a similar way.&lt;/p&gt;

&lt;h3&gt;Extra Documents in Elasticsearch&lt;/h3&gt;

&lt;p&gt;With the set up in the &lt;a href="https://aranair.github.io/posts/2016/12/14/aws-emr-pig-index-into-elasticsearch/"&gt;previous post&lt;/a&gt;, the EMR cluster starts the data ETL (Extract, Transform, Load) and indexes to
the Elasticsearch cluster. I had already let it run for a day or two, before I noticed an issue. &lt;/p&gt;

&lt;p&gt;I had finished one batch of data, which was about &lt;code&gt;20-25 million&lt;/code&gt; rows, I noticed that there were way 
more indexed documents than actual data! There were consistently &lt;code&gt;2-3 million&lt;/code&gt; more rows
than actual data. It certainly isn&amp;rsquo;t a neglible difference.&lt;/p&gt;

&lt;p&gt;From EMR stats, I could see how many rows the cluster has processed and the number there was actually correct?!
I was puzzled at why this was happening.&lt;/p&gt;

&lt;h3&gt;Hypothesis&lt;/h3&gt;

&lt;p&gt;I came up with a few hypothesis at first:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;EMR tasks consume too much memory, causing EMR jobs to fail and retry.
causing EMR tasks to fail and retry.&lt;/li&gt;
&lt;li&gt;Too little memory reserved for Elasticsearch heap size.&lt;/li&gt;
&lt;li&gt;Pig script not handling rejection of documents properly, causing retries.&lt;/li&gt;
&lt;li&gt;Pig script parallelism was too high; Elasticsearch cluster was getting overloaded by the indexing,&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;All of the above, technically, could cause duplicates to be sent to Elasticsearch. I did end up 
making a few changes to configs before it eventually worked and learnt a few things along the way!&lt;/p&gt;

&lt;p&gt;Below, I document some of the steps I took before I found out why. Some of these are actually
helpful even if you don&amp;rsquo;t run into this issue but if you&amp;rsquo;ll like to skip right to the solution, fast-forward 
to the last section ;)&lt;/p&gt;

&lt;h3&gt;Tweaking Elasticsearch&lt;/h3&gt;

&lt;p&gt;I increased the memory allocation in ECS for the Elasticsearch task, and made some temporary changes to the
to the Elasticsearch index settings during the indexing phase:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;"settings": {
  "index": {
    "number_of_shards":5,
    "number_of_replicas":0,
    "max_result_window":1,
    "refresh_interval":"-1"
  },
  ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This stops the &lt;code&gt;refresh&lt;/code&gt; of the index and stops &lt;code&gt;replica propagation&lt;/code&gt; during the indexing to reduce flow of
data. After the indexing is done, I would revert it back to normal via:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;"settings": {
  "index": {
      "number_of_replicas": 2,
      "max_result_window": 10000,
      "refresh_interval" : "30s"
  },
  ...
}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The combination of the memory increase and the above tweaks did speed up the indexing process overall 
but the duplicate documents were still getting indexed after. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Hypothesis rejected&lt;/em&gt;.&lt;/p&gt;

&lt;h3&gt;Pig Script&lt;/h3&gt;

&lt;p&gt;First, I lowered the parallelism in the Pig Script to get it to index slower (just to eliminate this as a problem).
Unfortunately, later on I found out that the parallelism is only used for certain operations like group/join etc. &lt;em&gt;Dead-end&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;Then I found out that the &lt;code&gt;elasticsearch-hadoop-pig-2.3.4&lt;/code&gt; plugin already handles document rejection 
and retries properly. &lt;/p&gt;

&lt;p&gt;&lt;em&gt;Great, another dead-end!&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;EMR Memory Usage&lt;/h3&gt;

&lt;p&gt;I then tried to change the EMR cluster&amp;rsquo;s task instance sizes to have about &lt;code&gt;60GB&lt;/code&gt; memory to get that possibility 
out of the way. (It was also at that point, I learnt that only a few instance types are available for selection for spot 
instance bidding). &lt;/p&gt;

&lt;p&gt;&lt;em&gt;That too didn&amp;rsquo;t help.&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;Hadoop Speculative Execution&lt;/h3&gt;

&lt;p&gt;let me just quickly run through what is speculative execution; it is a feature built to 
combat random delays and slowdowns in a distribution environment.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;As the EMR cluster processes data, some machines would naturally finish their task quicker than others.

To prevent a system-wide slowdown because of the slower tasks, Hadoop always tries to detect slower-than-expected machines/jobs and assigns a replica of their tasks to other free nodes (or spins up new nodes), as a backup. 

The node that finishes first, would be considered successful; the other slower ones would be killed.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This, as you might expect, would create a ton of problems for Elasticsearch indexing tasks.&lt;/p&gt;

&lt;p&gt;Towards the end of each indexing cycle, Elasticsearch would slow down by a fraction and Hadoop 
would detect the slowdown and spin up all those backup tasks that would be indexing the exact 
same data at the same time! Since I left the &lt;code&gt;id&lt;/code&gt; generation to Elasticsearch (recommended), this would
ultimately cause the duplicates I saw.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Finally!&lt;/em&gt;&lt;/p&gt;

&lt;h3&gt;How Do I Fix It Then?&lt;/h3&gt;

&lt;p&gt;For me, there were 2 ways out.&lt;/p&gt;

&lt;p&gt;I could generate a composite column to serve as an unique &lt;code&gt;id&lt;/code&gt; for each Elasticsearch row that is indexed, 
so that even if they were duplicated, Elasticsearch would be able to throw away all the duplicate ones. 
However, this was entirely not viable for the data I was indexing as the composite column would 
take up so much space it wouldn&amp;rsquo;t really be worth it.&lt;/p&gt;

&lt;p&gt;The way I chose was to disable the speculative execution in the Hadoop environment altogether. &lt;/p&gt;

&lt;p&gt;For EMR software version 4 and below, you could re-define the bootstrap action for the Hadoop environment.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;"bootstrapAction": [
  "s3://us-east-1.elasticmapreduce/bootstrap-actions/configure-hadoop,-m,mapred.map.tasks.speculative.execution=false,-m,mapred.reduce.tasks.speculative.execution=false"
],
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For API version 5+, you would need to do it via the &lt;code&gt;mapred-site&lt;/code&gt; classification via configuration JSON files.
You can read more about them in &lt;a href="http://docs.aws.amazon.com/ElasticMapReduce/latest/ReleaseGuide/emr-configure-apps.html"&gt;this documentation&lt;/a&gt; for EMR V5.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;[
  {
    "Classification": "mapred-site",
    "Properties": {
      "mapred.map.tasks.speculative.execution": "false",
      "mapred.reduce.tasks.speculative.execution": "false"
    }
  }
]
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Round up&lt;/h3&gt;

&lt;p&gt;I hope my learnings can help anyone out there facing a similar issue; do let me know in the comments
if you have any questions!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>How to set up Amazon EMR Hadoop with Pig to index to Elasticsearch</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/12/14/aws-emr-pig-index-into-elasticsearch/"/>
    <id>http://blog.url.com/posts/2016/12/14/aws-emr-pig-index-into-elasticsearch/</id>
    <published>2016-12-14T00:00:00+08:00</published>
    <updated>2016-12-14T21:54:42+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;In one of my &lt;a href="https://aranair.github.io/posts/2016/11/22/aws-elasticsearch-elastic-cloud-self-managed/"&gt;recent posts&lt;/a&gt;, I briefly talked about using &lt;code&gt;Apache Pig&lt;/code&gt;, to index an
Elasticsearch cluster. In this post, I do a walkthrough of the DevOps configurations and steps I took, along with the code
that was required to get it work at the start (barring some issues that I&amp;rsquo;ll talk about in the next post).&lt;/p&gt;

&lt;h3&gt;Production Setup&lt;/h3&gt;

&lt;p&gt;The process starts with &lt;code&gt;Jenkins&lt;/code&gt;; it uses &lt;code&gt;aws-cli&lt;/code&gt; to build an &lt;code&gt;AWS DataPipeLine&lt;/code&gt; with config variables. This DataPipeline,
with the loaded &lt;code&gt;JSON&lt;/code&gt; configurations, would then provision an Amazon EMR Hadoop cluster for the actual task.&lt;/p&gt;

&lt;p&gt;While &lt;code&gt;Jenkins&lt;/code&gt; could probably be entirely removed and a build be just triggered via DataPipeline or even EMR directly,
I feel that, this way, other devs don&amp;rsquo;t have to know about certain services in AWS?&lt;/p&gt;

&lt;p&gt;Most importantly, this abstraction takes some cognitive load off them.&lt;/p&gt;

&lt;h3&gt;Jenkins&lt;/h3&gt;

&lt;p&gt;This line in &lt;code&gt;Jenkins&lt;/code&gt; creates a &lt;code&gt;DataPipeLine&lt;/code&gt; using json config files in the code.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;aws datapipeline put-pipeline-definition &lt;span class="se"&gt;\&lt;/span&gt;
  --region &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;AWS_REGION&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --pipeline-id &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PIPELINE_ID&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
  --pipeline-definition file://pipeline/emr_cluster_pipeline.json &lt;span class="se"&gt;\&lt;/span&gt;
  --parameter-values-uri &lt;span class="s1"&gt;'file://'&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PROPS_FILE&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can read more about &lt;code&gt;pipeline-definition&lt;/code&gt; and &lt;code&gt;--parameter-values-uri&lt;/code&gt; in the &lt;a href="http://docs.aws.amazon.com/datapipeline/latest/DeveloperGuide/dp-custom-templates.html"&gt;AWS documentation&lt;/a&gt;.&lt;/p&gt;

&lt;h3&gt;DataPipeLine&lt;/h3&gt;

&lt;p&gt;Let&amp;rsquo;s move on to the pipeline definition files. I used something similar to this (obviously stripping away the sensitive data):&lt;/p&gt;
&lt;pre class="highlight json"&gt;&lt;code&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="s2"&gt;"objects"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"id"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Default"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Default"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"failureAndRerunMode"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"CASCADE"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"schedule"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="s2"&gt;"ref"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"DefaultSchedule"&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"resourceRole"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"DataPipelineDefaultResourceRole"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"role"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"DataPipelineDefaultRole"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"scheduleType"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"cron"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"pipelineLogUri"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"#{myLogsFolder}"&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"id"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"RunJobs"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"Run the Jobs"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"ShellCommandActivity"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"command"&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"aws s3 cp #{s3SoftwareFolder} . --recursive; sh init-script.sh --verbose --run-es-pig --es-endpoint #{myEsEndpoint}"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"runsOn"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="s2"&gt;"ref"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"EMR_Cluster"&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"schedule"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="s2"&gt;"ref"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"DefaultSchedule"&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"id"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"EMR_Cluster"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"name"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"EMR Cluster"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"type"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"EmrCluster"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"masterInstanceType"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"m3.xlarge"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"coreInstanceType"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"m3.xlarge"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"coreInstanceCount"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"5"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"taskInstanceType"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"r3.2xlarge"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"taskInstanceCount"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"5"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"taskInstanceBidPrice"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="mf"&gt;0.3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"region"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"us-east-1"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"subnetId"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"subnet-xxxxx"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"keyPair"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"some-keypair "&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"emrManagedMasterSecurityGroupId"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"sg-xxxxxx"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"emrManagedSlaveSecurityGroupId"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"sg-xxxxxx"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"terminateAfter"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"6 HOURS"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"enableDebugging"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"true"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"actionOnTaskFailure"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"terminate"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"actionOnResourceFailure"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="s2"&gt;"retrynone"&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="s2"&gt;"schedule"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;&lt;span class="w"&gt;
        &lt;/span&gt;&lt;span class="s2"&gt;"ref"&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="w"&gt; &lt;/span&gt;&lt;span class="s2"&gt;"DefaultSchedule"&lt;/span&gt;&lt;span class="w"&gt;
      &lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="p"&gt;},&lt;/span&gt;&lt;span class="w"&gt;
    &lt;/span&gt;&lt;span class="err"&gt;...&lt;/span&gt;&lt;span class="w"&gt;
  &lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="w"&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The config above tells &lt;code&gt;DataPipeLine&lt;/code&gt; to launch the EMR cluster with the id &lt;code&gt;EMR_Cluster&lt;/code&gt; that contains one &lt;code&gt;m3.xlarge&lt;/code&gt; master instance
and five &lt;code&gt;m3.xlarge&lt;/code&gt; core instances.&lt;/p&gt;

&lt;h4&gt;Task Instances&lt;/h4&gt;

&lt;p&gt;For the task instances, it bids for up to 5 &lt;code&gt;r3.2xlarge&lt;/code&gt; spot instances with a cost of &lt;code&gt;$0.30&lt;/code&gt;
per instance hour. That&amp;rsquo;s a discount of approximately &lt;code&gt;$0.088&lt;/code&gt;?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Do note that, not all instances are available as task instances&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The EMR pipeline will eventually execute the command below; it first copies essential libraries like 
maven jar files that into S3. As you&amp;rsquo;ll see later, these libraries will be used in the task instances later.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;aws s3 cp #{s3SoftwareFolder} . --recursive; sh init-script.sh --verbose --run-es-pig --es-endpoint #{myEsEndpoint}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;The Bash Script&lt;/h3&gt;

&lt;p&gt;It also executes &lt;code&gt;init-script.sh&lt;/code&gt;. I had a bunch of other variable preparation in there but most importantly,
I pre-created the Elasticsearch index because the index that is automatically created by Pig Script
doesn&amp;rsquo;t match what I want.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;curl -XPUT &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ES_ENDPOINT&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/data_&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;DAY_EPOCH&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/"&lt;/span&gt; -d &lt;span class="s1"&gt;'{
  "mappings":{
     "publisher":{
        "properties":{
           "country":{ "type":"string" },
           ...
        }
     }
   }
}'&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;It also handles some miscellaneous tasks like swapping of the Elasticsearch aliases and deleting old ones.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;curl -XPOST &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ES_ENDPOINT&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/_aliases"&lt;/span&gt; -d &lt;span class="s1"&gt;'
{
  "actions" : [
    { "remove" : { "index" : "data_*", "alias" : "data_latest" } },
    { "add" : { "index" : "data_'&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;DAY_EPOCH&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s1"&gt;'", "alias" : "data_latest" } }
  ]
}'&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Running the Pig Script&lt;/h3&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;pig -F -param &lt;span class="nv"&gt;ES_ENDPOINT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;ES_ENDPOINT&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
       -param &lt;span class="nv"&gt;INPUT&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;INPUT&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
       -param &lt;span class="nv"&gt;DAY_EPOCH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;DAY_EPOCH&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; -f &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;PHYS_DIR&lt;/span&gt;&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;/index-data.q"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;These would automatically run in the spot instances for non-group operations. One thing to note, is that the &lt;code&gt;INPUT&lt;/code&gt; variable
is where I define the S3 path to the Hadoop hdfs files to be ingested and indexed.&lt;/p&gt;

&lt;p&gt;This &lt;strong&gt;should not&lt;/strong&gt; be a local folder because the spot instances do not have access to them at runtime and will fail.&lt;/p&gt;

&lt;h3&gt;Inside the Pig Script&lt;/h3&gt;

&lt;p&gt;Next, I register the required jar files; these are actually just maven files.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;REGISTER piggybank.jar;
REGISTER s3://S3_BUCKET_NAME/software/libs/elasticsearch-hadoop-pig-2.3.4.jar;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set the parallelism for this pig script to run in (given the right resources via the EMR cluster).&lt;/p&gt;

&lt;p&gt;To be fair, in this particular example, this parallelism is not used.
It is only really taken into consideration for group, co-group and join operations.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;SET default_parallel 20;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Initialize the libraries and start the ingesting of the data.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;DEFINE CsvLoader org.apache.pig.piggybank.storage.CSVExcelStorage(',');
DEFINE EsStorage org.elasticsearch.hadoop.pig.EsStorage('es.nodes=$ES_ENDPOINT','es.http.timeout=5m');
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The &lt;code&gt;$ES_ENDPOINT&lt;/code&gt; variable is a comma delimited variable that has the ports included as well, e.g. &lt;code&gt;52.167.183.192:9200&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;There are other variables that you can define here such as &lt;code&gt;es.mapping.id&lt;/code&gt; that defines the id for the Elasticsearch for example,
instead of automatically letting Elasticsearch generate one.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;raw_data = LOAD '$INPUT'
           USING CsvLoader AS (
             bundle_id:chararray,
             publisher:chararray,
             exchange_id:int,
             country:chararray,
             categories:chararray,
             ad_size:chararray,
             interstitial:int,
             apis:chararray,
             platform_id:int,
             device_os_id:int,
             video_type:int,
             ad_type:int,
             app_id:chararray,
             publisher_id:chararray,
             assets:chararray,
             frequency:long);
&lt;/code&gt;&lt;/pre&gt;
&lt;h4&gt;Extract, Transform, Load&lt;/h4&gt;

&lt;p&gt;This last step runs through each of the rows of the data and generates a subset of the data to be indexed into Elasticsearch.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;filtered_data = FOREACH raw_data
                GENERATE $0, $1, $2, $3, $4, $5, $7, $8, $9, $10, $11, $14, $15;

STORE filtered_data INTO 'data_$DAY_EPOCH/publisher' USING EsStorage();
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You could do many different variations of ETL in Pig Script. For instance, you can combine some of the columns
into one column.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;ve found that in Pig &lt;code&gt;v0.12.0&lt;/code&gt;, concatenation of multiple columns is quite finicky because you can&amp;rsquo;t
combine multiple columns at one time; it has to be sequential like this:&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;d = FOREACH raw_data
    GENERATE
      CONCAT($0, (chararray)CONCAT($1, (chararray)CONCAT($2, $3))) as id, $4, $5, $6;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Note that, without the &lt;code&gt;(chararray)&lt;/code&gt;, you quickly run into errors about forcing an explicit type cast.&lt;/p&gt;

&lt;h3&gt;Summary&lt;/h3&gt;

&lt;p&gt;I&amp;rsquo;ve done an run-through of each of the components in a production setup: &lt;code&gt;Jenkins&lt;/code&gt;, &lt;code&gt;DataPipeline&lt;/code&gt;, &lt;code&gt;EMR/Pig&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I hope this helps people out there figure out how to spin up, either periodically or on-demand, 
an Amazon EMR cluster running Hadoop to do some basic ETL to then index into an Elasticsearch cluster.&lt;/p&gt;

&lt;p&gt;In the next post, I shall discuss some of the pitfalls, EMR / Elasticsearch performance tuning 
issues that leads to random failures in the EMR cluster. All of them could cause some rather tricky issues 
in the indexing task; one of the ones that I have personally experienced myself is having 
duplicated documents in the Elasticsearch cluster despite having only processed a correct number of them.&lt;/p&gt;

&lt;p&gt;If you have any questions, feel free to comment below!&lt;/p&gt;
</content>
  </entry>
  <entry>
    <title>How to set up Elasticsearch Cluster in Amazon ECS</title>
    <link rel="alternate" href="http://blog.url.com/posts/2016/12/05/aws-ecs-elasticsearch-cluster/"/>
    <id>http://blog.url.com/posts/2016/12/05/aws-ecs-elasticsearch-cluster/</id>
    <published>2016-12-05T00:00:00+08:00</published>
    <updated>2016-12-14T22:38:02+08:00</updated>
    <author>
      <name>Article Author</name>
    </author>
    <content type="html">&lt;p&gt;At Pocketmath, we heavily utilize the EC2 container service (ECS) to host a significant portion of our applications. It provides us with an easily scalable, zero-downtime infrastructure. Recently, I upgraded the Elasticsearch to &lt;code&gt;2.3.5&lt;/code&gt; for our clusters, so I thought it was a good idea just to jot down some of the things I had to do or was already
there for it to function properly.&lt;/p&gt;

&lt;h3&gt;Preface&lt;/h3&gt;

&lt;p&gt;If you&amp;rsquo;ll like to skip to the end and just take a look at the Docker-compose, task definitions and config files, feel
free to skip right to &lt;a href="https://github.com/aranair/docker-elasticsearch-ecs"&gt;the github repository&lt;/a&gt; that I&amp;rsquo;ve prepared to contain all this!&lt;/p&gt;

&lt;h3&gt;Dockerfile&lt;/h3&gt;

&lt;p&gt;First, I had to change the destination as well as the syntax for the plugin installs.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;FROM elasticsearch:2.3

WORKDIR /usr/share/elasticsearch

RUN bin/plugin install cloud-aws
RUN bin/plugin install mobz/elasticsearch-head
RUN bin/plugin install analysis-phonetic

COPY elasticsearch.yml config/elasticsearch.yml
COPY logging.yml config/logging.yml
COPY elasticsearch-entrypoint.sh /docker-entrypoint.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Docker &amp;amp; Elasticsearch Setup&lt;/h3&gt;

&lt;p&gt;Do take note that the &lt;code&gt;network.host&lt;/code&gt; is required for &lt;strong&gt;Zen Discovery&lt;/strong&gt; to work in ECS.&lt;/p&gt;

&lt;p&gt;It&amp;rsquo;s a simple dockerized container setup with mounted volumes in a separate data container and exposed ports for
elasticsearch communication.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;docker-compose.yml&lt;/code&gt; sample:&lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="na"&gt;services&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
  &lt;span class="na"&gt;data&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
    &lt;span class="na"&gt;build&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;./docker-data/&lt;/span&gt;
    &lt;span class="na"&gt;volumes&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;/usr/share/elasticsearch/data&lt;/span&gt;

  &lt;span class="na"&gt;search&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
    &lt;span class="na"&gt;build&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;./docker-elasticsearch/&lt;/span&gt;
    &lt;span class="na"&gt;volumes_from&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s"&gt;data&lt;/span&gt;
    &lt;span class="na"&gt;ports&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="s"&gt;9200:9200"&lt;/span&gt;
      &lt;span class="pi"&gt;-&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="s"&gt;9300:9300"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;elasticsearch.yml:&lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="s"&gt;script.inline&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;true&lt;/span&gt;
&lt;span class="s"&gt;bootstrap.mlockall&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;true&lt;/span&gt;

&lt;span class="s"&gt;network.host&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;0.0.0.0&lt;/span&gt;
&lt;span class="s"&gt;plugin.mandatory&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;cloud-aws&lt;/span&gt;
&lt;span class="s"&gt;network.publish_host&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;_ec2:privateIp_&lt;/span&gt;
&lt;span class="s"&gt;discovery.type&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;ec2&lt;/span&gt;
&lt;span class="s"&gt;discovery.ec2.groups&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;xx-xxxxx&lt;/span&gt;
&lt;span class="s"&gt;discovery.zen.ping.multicast.enabled&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The first two lines are fairly standard, so I&amp;rsquo;ll skip them; you can find these around in the official docs. It&amp;rsquo;s the last
few lines that I had to meddle around with a bit for it to work.&lt;/p&gt;

&lt;h3&gt;Discovery&lt;/h3&gt;

&lt;p&gt;So, the default node discovery module for Elasticsearch is &lt;a href="https://www.elastic.co/guide/en/elasticsearch/reference/5.x/modules-discovery-zen.html"&gt;Zen Discovery&lt;/a&gt;, and it supports both multicast and unicast.
Although, since EC2 &lt;a href="https://aws.amazon.com/vpc/faqs/"&gt;doesn&amp;rsquo;t support multicast&lt;/a&gt;, I disabled multicast and used only unicast. There are some
notable things that were in that docs, though: &lt;strong&gt;the ping (discovery)&lt;/strong&gt; and &lt;strong&gt;the master election&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;During the &lt;code&gt;ping phase&lt;/code&gt;, each node uses the discovery mechanism to find other nodes in the cluster. That process, however,
won&amp;rsquo;t work out-of-the-box for cloud environments like Elastic Cloud or AWS EC2. There is a plugin that fixes this- &lt;code&gt;cloud-aws&lt;/code&gt;. So I installed it via the Dockerfile above, for each container that runs inside
the cluster. One issue is that the plugin was built for EC2 where each instance naturally publishes their own instance&amp;rsquo;s IP
for the discovery process. Inside ECS, that discovery mechanism will fail since it just publishes its container&amp;rsquo;s IP address.&lt;/p&gt;

&lt;h3&gt;Running it in ECS&lt;/h3&gt;

&lt;p&gt;Back in Elasticsearch V1, I think the code below was the de-facto solution as an entry point for Docker. It pings Amazon&amp;rsquo;s &lt;code&gt;169.254.169.254&lt;/code&gt; instance information endpoint for the private IP. You could then start the service with its container&amp;rsquo;s IP as the published address; this address allows for other nodes to connect to it.  A reasonably updated
&lt;a href="https://github.com/daptiv/elasticsearch-ecs"&gt;github repo&lt;/a&gt; still uses this method. &lt;strong&gt;And it still works.&lt;/strong&gt; But there is a cleaner way now.&lt;/p&gt;
&lt;pre class="highlight shell"&gt;&lt;code&gt;&lt;span class="c"&gt;#!/bin/bash&lt;/span&gt;

&lt;span class="nb"&gt;set&lt;/span&gt; -e

&lt;span class="c"&gt;# Add elasticsearch as command if needed&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="k"&gt;${&lt;/span&gt;&lt;span class="nv"&gt;1&lt;/span&gt;:0:1&lt;span class="k"&gt;}&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'-'&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;; &lt;span class="k"&gt;then
    &lt;/span&gt;&lt;span class="nb"&gt;set&lt;/span&gt; -- elasticsearch &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c"&gt;# Drop root privileges if we are running elasticsearch&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="o"&gt;[&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$1&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'elasticsearch'&lt;/span&gt; &lt;span class="o"&gt;]&lt;/span&gt;; &lt;span class="k"&gt;then&lt;/span&gt;
    &lt;span class="c"&gt;# Change the ownership of /usr/share/elasticsearch/data to elasticsearch&lt;/span&gt;
    chown -R elasticsearch:elasticsearch /usr/share/elasticsearch/data
    &lt;span class="nb"&gt;exec &lt;/span&gt;gosu elasticsearch &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;span class="k"&gt;fi&lt;/span&gt;

&lt;span class="c"&gt;# ECS will report the docker interface without help, so we override that with host's private IP&lt;/span&gt;
&lt;span class="nv"&gt;AWS_PRIVATE_IP&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="sb"&gt;`&lt;/span&gt;curl http://169.254.169.254/latest/meta-data/local-ipv4&lt;span class="sb"&gt;`&lt;/span&gt;
&lt;span class="nb"&gt;set&lt;/span&gt; -- &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt; --network.publish_host&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nv"&gt;$AWS_PRIVATE_IP&lt;/span&gt;

&lt;span class="c"&gt;# As argument is not related to elasticsearch,&lt;/span&gt;
&lt;span class="c"&gt;# then assume that user wants to run his process.&lt;/span&gt;
&lt;span class="c"&gt;# For example, a `bash` shell to explore this image&lt;/span&gt;
&lt;span class="nb"&gt;exec&lt;/span&gt; &lt;span class="s2"&gt;"&lt;/span&gt;&lt;span class="nv"&gt;$@&lt;/span&gt;&lt;span class="s2"&gt;"&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now, just open up port 9200/9300 for communication within the security groups, and that&amp;rsquo;s it!&lt;/p&gt;

&lt;h3&gt;Cleaner, you say?&lt;/h3&gt;

&lt;p&gt;In later versions, (along with t cloud-aws plugin versions), you can now &lt;code&gt;_ec2:privateIp_&lt;/code&gt; in the elasticsearch.yml file.&lt;/p&gt;
&lt;pre class="highlight yaml"&gt;&lt;code&gt;&lt;span class="s"&gt;network.host&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;0.0.0.0&lt;/span&gt;
&lt;span class="s"&gt;plugin.mandatory&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;cloud-aws&lt;/span&gt;
&lt;span class="s"&gt;network.publish_host&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;_ec2:privateIp_&lt;/span&gt;
&lt;span class="s"&gt;discovery.type&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;ec2&lt;/span&gt;
&lt;span class="s"&gt;discovery.ec2.groups&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;xx-xxxxx&lt;/span&gt;
&lt;span class="s"&gt;discovery.zen.ping.multicast.enabled&lt;/span&gt;&lt;span class="pi"&gt;:&lt;/span&gt; &lt;span class="s"&gt;false&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Master Election, and why it is important&lt;/h3&gt;

&lt;p&gt;Next, we go on to the master election part of the cluster.&lt;/p&gt;

&lt;p&gt;Like all distributed systems, the master/leader election is an important process that allows a cluster to choose its &lt;code&gt;brain&lt;/code&gt;,
for the purpose of handling allocations, state maintenance, index creations, etc. It is vital to the health of the cluster.
Elastic.co has a comprehensive &lt;a href="https://www.elastic.co/blog/found-leader-election-in-general"&gt;blog post&lt;/a&gt;, and you can read a quick intro there.&lt;/p&gt;

&lt;p&gt;In this context, I could set a minimum number of master nodes.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;The discovery.zen.minimum_master_nodes sets the minimum number of master eligible nodes that need to join a newly elected master for an election to complete and for the elected node to accept its mastership.
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We need to set the minimum number to a quorum (a majority wins situation) otherwise, the cluster is inoperable.
You can read more about the split-brain scenario &lt;a href="http://blog.trifork.com/2013/10/24/how-to-avoid-the-split-brain-problem-in-elasticsearch/"&gt;here&lt;/a&gt;. For automatic election, having only 2
master-eligible nodes should be avoided, since a quorum of 2 is 2 and a loss of either master-eligible nodes
will result in the split-brain state.&lt;/p&gt;

&lt;p&gt;If you dynamically scale your clusters, the below command would help with dynamically changing that number as you grow
your cluster.&lt;/p&gt;
&lt;pre class="highlight plaintext"&gt;&lt;code&gt;PUT /_cluster/settings
{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3&gt;Container memory limit and Heap Size&lt;/h3&gt;

&lt;p&gt;Next, this is something that gets tricky if you deploy to ECS and use the default settings.&lt;/p&gt;

&lt;p&gt;In my case, my task definitions were set to 1 GB, and the Elasticsearch service was running with a default of 1gb heap size.
After deploying to ECS, I noticed my docker container was just repeatedly getting stopped and restarted by the ECS agent.&lt;/p&gt;

&lt;p&gt;There were no errors; and elasticsearch logs just announced that it was shutting itself down, gracefully.&lt;/p&gt;

&lt;p&gt;At that point, I tweaked the memory hard limits via the task definitions in ECS and the restarts stopped.
The heap size that the Elasticsearch service was using was hitting beyond the hard memory limit of the container;
so the containers was repeatedly asked to restart.&lt;/p&gt;

&lt;p&gt;So if you&amp;rsquo;re deploying these docker containers to ECS, &lt;strong&gt;its good practice to set a hard memory limit to the ECS task definition!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;On top of that, you should also run the containers with the environment variable &lt;code&gt;ES_HEAP_SIZE=2g&lt;/code&gt;. The value there should be
roughly half the size of the hard memory limit in ECS to prevent the above scenario from happening.&lt;/p&gt;

&lt;h3&gt;Roundup&lt;/h3&gt;

&lt;p&gt;That&amp;rsquo;s it! I hope this post has helped you get your cluster setup in the ECS.&lt;/p&gt;

&lt;p&gt;Feel free to checkout &lt;a href="https://github.com/aranair/docker-elasticsearch-ecs"&gt;this github repository&lt;/a&gt; that I&amp;rsquo;ve put together the code I&amp;rsquo;ve talked about!&lt;/p&gt;

&lt;p&gt;Do check back in a week or two!&lt;/p&gt;
</content>
  </entry>
</feed>
